{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lfw_face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVPEiePQcA--",
        "outputId": "43a22526-da1a-4a25-cf9f-39f2b6963b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.72-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 62 kB 553 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.7.0)\n",
            "Collecting retina-face>=0.0.1\n",
            "  Downloading retina_face-0.0.9-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.3.5)\n",
            "Collecting mtcnn>=0.1.0\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.62.3)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.7.0)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.19.5)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.4.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (4.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->deepface) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2018.9)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.23.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.9.0->deepface) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.9.0->deepface) (3.1.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Installing collected packages: retina-face, mtcnn, deepface\n",
            "Successfully installed deepface-0.0.72 mtcnn-0.1.1 retina-face-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjO_NjkZWKAc",
        "outputId": "b5ecd918-d673-43b2-b63f-16b10178211f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ]
        }
      ],
      "source": [
        "# Module / package imports\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import zipfile\n",
        "import tarfile\n",
        "import requests\n",
        "import numpy              as np\n",
        "import pandas             as pd\n",
        "import matplotlib.pyplot  as plt\n",
        "import matplotlib.image   as mpimg\n",
        "import matplotlib.patches as patches\n",
        "import tensorflow         as tf\n",
        "\n",
        "tf_version = int(tf.__version__.split(\".\")[0])\n",
        "\n",
        "if tf_version == 2:\n",
        "    import logging\n",
        "    tf.get_logger().setLevel(logging.ERROR)\n",
        "    from tensorflow.keras.preprocessing import image\n",
        "else:\n",
        "    from keras.preprocessing import image\n",
        "\n",
        "from PIL                     import Image\n",
        "from io                      import BytesIO\n",
        "from deepface                import DeepFace\n",
        "from sklearn.metrics         import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "ROOT_DIR     = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "DATASETS_DIR = os.path.join(ROOT_DIR, \"data_sets\")\n",
        "\n",
        "#                0    ,     1    ,      2      ,     3     ,      4      ,      5     ,     6    ,   7\n",
        "BACKENDS = [  \"opencv\",     \"ssd\",       \"dlib\",    \"mtcnn\", \"retinaface\", \"mediapipe\"]\n",
        "MODELS   = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\",   \"DeepFace\",    \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
        "\n",
        "if len(tf.config.list_physical_devices('GPU')) == 0:\n",
        "  print('!!! WARNING !!!: No GPU found! This script might take longer\\\n",
        "  than expected if executed using only CPUs!')\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "class FR_performance:\n",
        "    \"\"\"\n",
        "    Face recognition performance class. Stores performance results and metrics\n",
        "    for the face recognition system using the specified face detector and\n",
        "    verifier.\n",
        "    \n",
        "    Attributes:\n",
        "        - On initialization:\n",
        "            1. name - name of result (typically \n",
        "                <face detector>_plus_<face verifier>)\n",
        "            2. files - name of files relating to these results\n",
        "            3. pred - predictions or face recognition system output (vector\n",
        "                of booleans representing match / no match for each file)\n",
        "                    \n",
        "        - After successful 'calc_performance' call:\n",
        "            4. acc - system's accuracy as a decimal\n",
        "            5. cm  - system's confusion matrix\n",
        "            6. tn  - system's true  negatives (absolute value)\n",
        "            7. fp  - system's false positives (absolute value)\n",
        "            8. fn  - system's false negatives (absolute value)\n",
        "            9. tp  - system's true  positives (absolute value)\n",
        "            \n",
        "        - After successful 'plot_performance' call:\n",
        "            10. txt  - text printed on the performance\n",
        "            11. disp - handle to performance plot\n",
        "            \n",
        "    Methods:\n",
        "        calc_performance(ground_truth) - calculates the performance of the \n",
        "            face recognition system by comparing the system's results with\n",
        "            the ground truth provided.\n",
        "            \n",
        "        plot_performance() - plots a confusion matrix showing the system's\n",
        "            performance, along with some important metrics: false positives,\n",
        "            false negatives, true positives, true negatives and accuracy.\n",
        "    \"\"\"\n",
        "    def __init__(self, name, output):\n",
        "        \"\"\"\n",
        "        Initializes the face recognition performance object.\n",
        "        \n",
        "        Inputs:\n",
        "            1. name - name of result\n",
        "            2. output - dictionary containing the file names and results\n",
        "            \n",
        "        Outputs:\n",
        "            Updates the following attributes:\n",
        "                a. name\n",
        "                b. files\n",
        "                c. pred\n",
        "        \"\"\"\n",
        "        self.name  = name\n",
        "        self.files = output[\"file\"]\n",
        "        self.pred  = output[\"result\"]\n",
        "        \n",
        "    def calc_performance(self, ground_truth):\n",
        "        \"\"\"\n",
        "        Calculates the performance of the face recognition system by\n",
        "        comparing the system's results with the ground truth provided.\n",
        "        \n",
        "        Input:\n",
        "            1. ground_truth - array of boolean values indicating if\n",
        "                the specific file has a match in the gallery or not\n",
        "                \n",
        "        Outputs:\n",
        "            Updates the following attributes:\n",
        "                a. pred\n",
        "                b. acc\n",
        "                c. cm\n",
        "                d. tn\n",
        "                e. fp\n",
        "                f. fn\n",
        "                g. tp\n",
        "        \"\"\"\n",
        "        # Converts predictions to numpy array if they are not\n",
        "        if not isinstance(self.pred, np.ndarray):\n",
        "            self.pred = np.array(self.pred)\n",
        "            \n",
        "        # Calculating accuracy\n",
        "        if not isinstance(ground_truth, np.ndarray):\n",
        "            ground_truth = np.array(ground_truth)   \n",
        "        self.acc = np.sum(ground_truth == self.pred) \\\n",
        "                 / ground_truth.shape[0]\n",
        "        \n",
        "        # Calculating confusion matrix and other performance metrics\n",
        "        self.cm = confusion_matrix(ground_truth, self.pred)\n",
        "        self.tn, self.fp, self.fn, self.tp = self.cm.ravel()\n",
        "        \n",
        "    def plot_performance(self):\n",
        "        \"\"\"\n",
        "        Plots a confusion matrix showing the system's performance, along\n",
        "        with some important metrics: false positives, false negatives,\n",
        "        true positives, true negatives and accuracy.\n",
        "        \n",
        "        Input:\n",
        "            None\n",
        "                \n",
        "        Outputs:\n",
        "            Updates the following attributes:\n",
        "                a. txt\n",
        "                b. disp\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Creating performance text\n",
        "            self.txt = \"Accuracy: {:.3f}%\".format(100*self.acc).center(30) \\\n",
        "                     + \"\\n\" + f\"True positive: {self.tp}\".rjust(20)        \\\n",
        "                     + f\" | False positive: {self.fp}\".rjust(20) + \"\\n\"    \\\n",
        "                     + f\"True negative: {self.tn}\".rjust(20)               \\\n",
        "                     + f\" | False negative: {self.fn}\".rjust(20)\n",
        "\n",
        "            # Create confusion matrix display\n",
        "            self.disp = ConfusionMatrixDisplay(confusion_matrix=self.cm,\n",
        "                                       display_labels=[\"negative\", \"positive\"])\n",
        "            \n",
        "            # Plots the results & text\n",
        "            self.disp.plot(cmap=\"Blues\")\n",
        "            plt.figtext(0.5, -0.2, self.txt, wrap=True,\n",
        "                        horizontalalignment='center', fontsize=12);\n",
        "            plt.title(self.name);\n",
        "            \n",
        "        except Exception as excpt:\n",
        "            print(excpt)  # print exception\n",
        "            print(f\"Type: {type(excpt)} | Args: {excpt.args}\")\n",
        "            print(\"Try calling 'calc_performance' once then calling this method.\")\n",
        "            \n",
        "# ============================================================================\n",
        "\n",
        "class DownloadExtract:\n",
        "  \"\"\"\n",
        "  Simple class to download and extract zip, tar or tar.gz file from url.\n",
        "  \"\"\"\n",
        "\n",
        "  def download_and_extract(url, destination, file_is=\"\", verbose=0):\n",
        "    \"\"\"\n",
        "    Downloads and extracts a zip, tar, tar.gz or tgz file from the specified\n",
        "    'url' to the destination folder 'destination'. If the file specified is not \n",
        "    one of those types then this method aborts with a warning.\n",
        "\n",
        "    Inputs:\n",
        "      1. url - string specifying the file's URL.\n",
        "\n",
        "      2. destination - string specifying a target directory for extraction.\n",
        "\n",
        "      3. file_is - string specifying the file type ([], zip, tar or tar.gz).\n",
        "         If file_is='' is used then this function tries to determine the file\n",
        "         type automatically from the file's URL.\n",
        "\n",
        "      4. verbose - controls the text output of the function ([0 = quiet],\n",
        "         1 = verbose).\n",
        "    \n",
        "    Outputs:\n",
        "      None\n",
        "    \n",
        "    Example call:\n",
        "      DownloadExtractZip.download_and_extract(url, destination, verbose=0)\n",
        "    \"\"\"\n",
        "    # Variable to skip last verbose statement\n",
        "    skip_last_msg = False\n",
        "\n",
        "    # Assigns a file_type number according to the 'file_is' input\n",
        "    if file_is == 'zip':\n",
        "      file_type = 1\n",
        "    elif file_is == 'tar':\n",
        "      file_type = 2\n",
        "    elif file_is == 'tar.gz' or file_is == 'tgz':\n",
        "      file_type = 3\n",
        "    else:\n",
        "      file_type = 0\n",
        "\n",
        "    if verbose:\n",
        "      print('Downloading Started')\n",
        "    \n",
        "    # Downloading the file by sending the request to the URL\n",
        "    req = requests.get(url, allow_redirects=True)\n",
        "    if verbose:\n",
        "      print('Downloading Completed\\nExtracting ...', end=' ')\n",
        "\n",
        "    # Determines file type from url and extracts the file\n",
        "    if url.endswith(\"zip\") or file_type == 1:\n",
        "      zfile = zipfile.ZipFile(BytesIO(req.content))\n",
        "      zfile.extractall(destination)\n",
        "\n",
        "    elif url.endswith(\"tar\") or file_type == 2:\n",
        "      tar = tarfile.open(\"r:\", fileobj=BytesIO(req.content))\n",
        "      tar.extractall(destination)\n",
        "      tar.close()\n",
        "\n",
        "    elif url.endswith(\"tar.gz\") or url.endswith(\"tgz\") or file_type == 3:\n",
        "      tar = tarfile.open(\"r:gz\", fileobj=BytesIO(req.content))\n",
        "      tar.extractall(destination)\n",
        "      tar.close()\n",
        "\n",
        "    else:\n",
        "      skip_last_msg=True\n",
        "      print('failed!\\n[Error] File type was not recognized \\\n",
        "            (not zip, tar, tar.gz or tgz)')\n",
        "\n",
        "    if verbose and not skip_last_msg:\n",
        "      print('done!')\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "# Create directory function\n",
        "def create_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Creates a directory at the specified directory path 'dir_path' IF it does not\n",
        "  exist. Returns a status of 0 is the directory was successfully created and \n",
        "  returns a status of 1 if a directory already exists.\n",
        "\n",
        "  Inputs:\n",
        "    1. dir_path - directory path of new directory.\n",
        "    \n",
        "  Outputs:\n",
        "    1. status - 0 to indicate success (directory creation) or 1 to indicate\n",
        "       failure (directory already exists)\n",
        "    \n",
        "  Example call:\n",
        "    status = create_dir(\"./this/is/a/directory/path\")\n",
        "  \"\"\"\n",
        "  # Create directory\n",
        "  try:\n",
        "    os.makedirs(dir_path)\n",
        "    status = 0\n",
        "  except FileExistsError:\n",
        "    # Directory already exists\n",
        "    status = 1\n",
        "\n",
        "  return status\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def split_single_multiple_imgs(dataset_dir):\n",
        "    \"\"\"\n",
        "    Splits the LFW data set into two sets:\n",
        "        1. single - each person has only a SINGLE image\n",
        "        2. multiple - each person has MULTIPLE images (>1)\n",
        "\n",
        "    Input:\n",
        "        1. dataset_dir - full path of the LFW data set directory\n",
        "\n",
        "    Output:\n",
        "        1. dictionary containing the names of the directories:\n",
        "            a. Of people with only 1 image (key: 'single')\n",
        "            b. Of people with more than 1 images (key: 'multiple')\n",
        "\n",
        "    Example call:\n",
        "        splits = split_single_multiple_imgs(dataset_dir)\n",
        "        splits['single']   # these directories contain only 1 image\n",
        "        splits['multiple'] # these directories contain >1 images\n",
        "    \"\"\"\n",
        "\n",
        "    # Initializes lists\n",
        "    multiple_imgs = []\n",
        "    single_img    = []\n",
        "\n",
        "    # Loops through each directory\n",
        "    for dir in os.listdir(dataset_dir):\n",
        "        dir_fp = os.path.join(dataset_dir, dir) # gets full path\n",
        "\n",
        "        # Only consider directories (ignore files)\n",
        "        if os.path.isdir(dir_fp):\n",
        "            nfiles = len(os.listdir(dir_fp)) # number of files in directory\n",
        "\n",
        "            # Determines if the directory has multiple images and assigns it\n",
        "            # to the appropriate list\n",
        "            if nfiles > 1:\n",
        "                multiple_imgs.append(dir)\n",
        "            else:\n",
        "                single_img.append(dir)\n",
        "\n",
        "    return {\"single\":single_img, \"multiple\":multiple_imgs}\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def create_sub_LFW(save_path, dataset_root, p1_idxs=[], p1_num=100, p2_num=100,\n",
        "                    p2_idxs=[], force_create=False):\n",
        "    \"\"\"\n",
        "    Creates a subset of the LFW data set. This subset consists of a mixture of:\n",
        "        1. 'p1_num' directories of people with only 1 image available.\n",
        "        2. 'p2_num' directories of people with >1 images available.\n",
        "\n",
        "    These directories are 'linearly' sampled. Alternatively, the user can\n",
        "    provide a numpy array of indices corresponding to which subdirectories \n",
        "    they wish to include in the subset. Note that 'p1_idxs' and 'p2_idxs'\n",
        "    correspond indices of subdirectories described as above and if they are\n",
        "    provided then 'p1_num' and 'p2_num' have no effect.\n",
        "\n",
        "    For example:\n",
        "        p1_idxs = numpy.array([1, 2])    -> ignores 'p1_num'\n",
        "        p2_idxs = numpy.array([1, 2, 3]) -> ignores 'p2_num'\n",
        "\n",
        "    Result in:\n",
        "        The subset will consist of the first 2 subdirectories with only 1 image\n",
        "        and the first 3 subdirectories with more than 1 images.\n",
        "\n",
        "    In all cases, the first image of EACH subdirectory that has multiple images\n",
        "    will be used to create the gallery (known faces). Everything else will be\n",
        "    treated as faces in the wild, called targets (unknown faces)\n",
        "\n",
        "    The 'force_create' flag controls if this function should create the subset\n",
        "    even if 'save_path' points to an already existing directory (assumed to be a\n",
        "    pre-existing data set). Note that if force_create=True then the old data set\n",
        "    is DELETED - so use it with care!\n",
        "\n",
        "    Inputs:\n",
        "        1. save_path - full path to location of the new data set\n",
        "\n",
        "        2. dataset_root - full path of the LFW data set\n",
        "\n",
        "        3. p1_idxs - numpy array of indices that determine which subdirectories\n",
        "            of people with 1 image should be included. If not provided, then\n",
        "            'p1_num' linearly-spaced subdirectories are selected ([p1_idxs=[]]).\n",
        "\n",
        "        4. p1_num - number of single image subdirectories to be selected\n",
        "            ([p1_num=100])\n",
        "\n",
        "        5. p2_idxs - numpy array of indices that determine which subdirectories\n",
        "            of people with >1 images should be included. If not provided, then\n",
        "            'p2_num' linearly-spaced subdirectories are selected ([p2_idxs=[]]).\n",
        "\n",
        "        6. p2_num - number of multiple image subdirectories to be selected\n",
        "            ([p2_num=100])\n",
        "\n",
        "        7. force_create - flag indicating if this function should create the\n",
        "            data set even if a directory exists in 'save_path'. This function\n",
        "            assumes that a directory in 'save_path' is a data set. If \n",
        "            'force_create=True', IT WILL DELETE EVERYTHING IN 'save_path', so\n",
        "            use it with caution ([force_create=False])!\n",
        "\n",
        "    Output:\n",
        "        None (creates a data set at 'save_path')\n",
        "\n",
        "    Example call:\n",
        "        SAVE_PATH = I/want/to/save/the/dataset/here\n",
        "        LFW_ROOT  = this/is/where/LFW/is/located\n",
        "\n",
        "        # Creating custom indicies\n",
        "        p1_idxs = numpy.array([1, 2])\n",
        "        p2_idxs = numpy.array([1, 2, 3, 4, 5])\n",
        "\n",
        "        # This will result in a very small subset of LFW\n",
        "        create_sub_LFW(SAVE_PATH, LFW_ROOT, p1_idxs=p1_idxs, p2_idxs=p2_idxs)\n",
        "    \"\"\"\n",
        "\n",
        "    if os.path.isdir(save_path) and not force_create:\n",
        "        # Aborts creating the data set as it already exists\n",
        "        print(\"LFW subset data set already exists!\")\n",
        "        return None\n",
        "    \n",
        "    elif os.path.isdir(save_path) and force_create:\n",
        "        # Since 'force_create' is True, delete the previous data set found\n",
        "        print(\"Forcing the creation of the data set. \" \\\n",
        "              + \"Removing existing data set.\")\n",
        "        shutil.rmtree(save_path) # should aways work because 'save_path' exists\n",
        "\n",
        "    else:\n",
        "        # Otherwise the data set does not exist, so proceed with creating it.\n",
        "        # This is similar to when 'force_create=True' but without the need to \n",
        "        # delete the previous data set (because there isnt any).\n",
        "        #       - This is kept here to improve code reability / understanding\n",
        "        pass\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Creates the new dataset root directory\n",
        "    gallery_path = os.path.join(save_path, \"gallery\")\n",
        "    targets_path = os.path.join(save_path, \"targets\")\n",
        "\n",
        "    os.mkdir(save_path)    # path to the new dataset\n",
        "    os.mkdir(gallery_path) # path to the 'known'   people (gallery)\n",
        "    os.mkdir(targets_path) # path to the 'unknown' people (targets)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Splits dataset into people with a single image and people with multiple\n",
        "    # images\n",
        "    splits   = split_single_multiple_imgs(dataset_root)\n",
        "    single   = splits[\"single\"]\n",
        "    multiple = splits[\"multiple\"]\n",
        "\n",
        "    # Create partition arrays (if not provided). If provided assumes it is\n",
        "    # properly constructed... maybe it shouldnt?\n",
        "    if not isinstance(p1_idxs, np.ndarray):\n",
        "        p1_idxs = np.linspace(0,   len(single)-1, num=p1_num).astype(int)\n",
        "\n",
        "    if not isinstance(p2_idxs, np.ndarray):\n",
        "        p2_idxs = np.linspace(0, len(multiple)-1, num=p2_num).astype(int)\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # First we will deal with single images\n",
        "    for idx in p1_idxs:\n",
        "        source_path  = os.path.join(dataset_root, single[idx])\n",
        "        targets_path = os.path.join(save_path, \"targets\", single[idx])\n",
        "\n",
        "        # Copy the entire directory\n",
        "        try:\n",
        "            shutil.copytree(source_path, targets_path)\n",
        "        except Exception as excpt:\n",
        "            print(\"Type: \", type(excpt),\n",
        "                  \" | Arguments: \", excpt.args,\n",
        "                  \" | Exception: \", excpt)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Then we will deal with multiple images and create the gallery:\n",
        "    for idx in p2_idxs:\n",
        "        source_path  = os.path.join(dataset_root, multiple[idx])\n",
        "        gallery_path = os.path.join(save_path, \"gallery\", multiple[idx])\n",
        "        targets_path = os.path.join(save_path, \"targets\", multiple[idx])\n",
        "    \n",
        "        # Create a directory in gallery and targets with person's name if needed\n",
        "        if not os.path.isdir(gallery_path):\n",
        "            os.mkdir(gallery_path)\n",
        "    \n",
        "        if not os.path.isdir(targets_path):\n",
        "            os.mkdir(targets_path)\n",
        "\n",
        "        # We will use the first file to build our gallery\n",
        "        # Get the files inside the current directory\n",
        "        file_names = os.listdir(source_path)\n",
        "        for j, name in enumerate(file_names):\n",
        "\n",
        "            try:\n",
        "                if j == 0:\n",
        "                    shutil.copy2(os.path.join(source_path , name), \n",
        "                                 os.path.join(gallery_path, name))\n",
        "                else:\n",
        "                    shutil.copy2(os.path.join(source_path , name), \n",
        "                                 os.path.join(targets_path, name))\n",
        "            except FileNotFoundError:\n",
        "                pass\n",
        "\n",
        "    return None\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def get_LFW_ground_truth(dataset_root):\n",
        "    \"\"\"\n",
        "    Gets the ground truth from the LFW data set (or subsets assuming they\n",
        "    have the same structure). Returns the ground truth names (ids), targets\n",
        "    names (ids) and each targets' match to the ground truth.\n",
        "    \n",
        "    Input:\n",
        "        1. dataset_root - full path to the root directory of the LFW data set\n",
        "    \n",
        "    Outputs:\n",
        "        1. list with each person's name in the gallery\n",
        "        2. dictionary where each file name is a key and has a corresponding\n",
        "            boolean (item) indicating if this file has a positive match in\n",
        "            the gallery\n",
        "            \n",
        "    Example call:\n",
        "        LFW_ROOT = this/is/my/path/to/the/LFW/data_set\n",
        "        gt_ids, tgt_ids, tgt_mtch = get_LFW_ground_truth(LFW_ROOT)\n",
        "    \"\"\"\n",
        "    # Sets up the gallery and targets paths\n",
        "    gallery_dir = os.path.join(dataset_root, \"gallery\")\n",
        "    targets_dir = os.path.join(dataset_root, \"targets\")\n",
        "    \n",
        "    # Loops through all directories in 'gallery', obtaining the ground truth\n",
        "    # from the directory names\n",
        "    gt_ids = []\n",
        "    for root, dirs, _junk in os.walk(gallery_dir):\n",
        "        for name in dirs:\n",
        "            files = os.listdir(os.path.join(root, name))\n",
        "            # The file names are Name_Surname_XXXX.jpg so just ignore the last\n",
        "            # 9 characters (as we dont need _XXXX.jpg, just the person's name)\n",
        "            gt_ids.append(files[0][:-9].lower())\n",
        "     \n",
        "    # Loops through all directories in 'target', obtaining the targets' names\n",
        "    # from the directory names and trying to match them to the ground truths\n",
        "    tgt_mtch = dict()\n",
        "    for root, dirs, _junk in os.walk(targets_dir):\n",
        "        for name in dirs:\n",
        "            files = os.listdir(os.path.join(root, name))\n",
        "            # The file names are Name_Surname_XXXX.jpg so just ignore the last\n",
        "            # 9 characters (as we dont need _XXXX.jpg, just the person's name)\n",
        "            for file in files:\n",
        "                file = file[:-4].lower() # gets the file name without extension\n",
        "                \n",
        "                # Append the new number to the existing array at this slot\n",
        "                tgt_mtch[file] = file[:-5] in gt_ids\n",
        "                \n",
        "    \n",
        "    return gt_ids, tgt_mtch\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def evaluate_FR_on_LFW(dataset_root, model_name=\"VGG-Face\",\n",
        "                       detector_backend=\"opencv\", show_prog=True):\n",
        "    \"\"\"\n",
        "    Evaluates the facial recognition system on the LFW data set (or subset,\n",
        "    assuming it has the same structure as LFW) using the specified face\n",
        "    verification model ('model_name') and face detector model\n",
        "    ('detector_backend'). A progress bar is shown if 'show_prog=True'.\n",
        "    \n",
        "    Inputs:\n",
        "        1. dataset_root - full path of the LFW data set (or subset) root\n",
        "        2. model_name - face verification model name ([VGG-Face], Facenet, \n",
        "            Facenet512, OpenFace, DeepFace, DeepID, ArcFace, Dlib)\n",
        "        3. detector_backend - face detector model name ([opencv], ssd, dlib,\n",
        "            mtcnn, retinaface, mediapipe)\n",
        "        4. show_prog - flag indicating if progress bars should be shown\n",
        "            ([show_prog=True])\n",
        "            \n",
        "    Output:\n",
        "        1. dictionary containing the file names (key: 'file'), ground truth\n",
        "            boolean value indicating if there is a match in the gallery (key:\n",
        "            'gt') and boolean value indicating if the face recognition system\n",
        "            found a match in the gallery (key: 'results')\n",
        "            \n",
        "    Note: 'results' can be interpreted as \"predictions\".\n",
        "    \n",
        "    Example call:\n",
        "        LFW_ROOT = this/is/my/path/to/the/LFW/data_set\n",
        "        output = evaluate_FR_on_LFW(dataset_root, model_name=\"Facenet\",\n",
        "                                  detector_backend=\"retinaface\", show_prog=True)\n",
        "    \"\"\"\n",
        "    # Sets up the gallery and targets paths\n",
        "    gallery_path = os.path.join(dataset_root, \"gallery\")\n",
        "    targets_path = os.path.join(dataset_root, \"targets\")\n",
        "    \n",
        "    # ------------------------------------------------------------------------\n",
        "    \n",
        "    # Gets the ground truths from the LFW data set\n",
        "    gt_ids, tgt_mtch = get_LFW_ground_truth(dataset_root)\n",
        "    \n",
        "    # ------------------------------------------------------------------------\n",
        "    \n",
        "    # Gets all targets\n",
        "    all_targets = []\n",
        "    for root, dirs, _junk in os.walk(targets_path):\n",
        "        for i, dir in enumerate(dirs):\n",
        "            files = os.listdir(os.path.join(root, dir))\n",
        "            for file in files:\n",
        "                all_targets.append(os.path.join(root, dir, file))\n",
        "                \n",
        "    # ------------------------------------------------------------------------\n",
        "\n",
        "    # Applies face recognition\n",
        "    results = DeepFace.find(img_path = all_targets,\n",
        "                            db_path = gallery_path,\n",
        "                            model_name = model_name,\n",
        "                            detector_backend = detector_backend,\n",
        "                            prog_bar = not show_prog) # dunno why prog_bar is inverted\n",
        "    \n",
        "    # ------------------------------------------------------------------------\n",
        "\n",
        "    # Process results\n",
        "    output = {\"file\": [], \"result\":[], \"gt\":[]} # initializes dictionary\n",
        "    for name, result in zip(all_targets, results):\n",
        "        # Processes and stores the file name\n",
        "        name = name.split(\"/\")[-1][:-4].lower() # extracts file's name\n",
        "        output[\"file\"].append(name)\n",
        "    \n",
        "        # If the current result dataframe is empty than no match was\n",
        "        # found (False), otherwise a match was found (True)\n",
        "        output[\"result\"].append(not result.empty)\n",
        "    \n",
        "        # Given the target name, searches the ground truth in the\n",
        "        # 'tgt_mtch' dictionary\n",
        "    \n",
        "        output[\"gt\"].append(tgt_mtch[name])\n",
        "        \n",
        "    return output\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "def get_and_plot_performance(predictions, ground_truth):\n",
        "    \"\"\"\n",
        "    Gets performance data and plots the confusion matrix as a performance\n",
        "    indicator. Returns the confusion matrix plot and a dictionary containing\n",
        "    the accuracy, true negative, false positive, false negative, true positive\n",
        "    and confusion matrix.\n",
        "    \n",
        "    Inputs:\n",
        "        1. predictions  - prediction list or numpy array of boolean values\n",
        "        2. ground_truth - ground_truth list or numpy array of boolean values\n",
        "        \n",
        "    Outputs:\n",
        "        1. handle to the confusion matrix plot\n",
        "        2. dictionary with:\n",
        "            a. 'acc': accuracy\n",
        "            b. 'tn': true negative\n",
        "            c. 'fp': false positive\n",
        "            d. 'fn': false negative\n",
        "            e. 'tp': true positive\n",
        "            f. 'cm': confusion matrix\n",
        "            \n",
        "    Example call:\n",
        "        disp, perf = get_and_plot_performance(pred, gts)\n",
        "    \"\"\"\n",
        "    # Creating the confusion matrix and calculating accuracy,\n",
        "    # true negative, true positive, false negative and false positive\n",
        "    acc            = 100 * np.sum(np.array(ground_truth) ==   \\\n",
        "                              np.array(predictions))          \\\n",
        "                     / len(ground_truth)\n",
        "    cm             = confusion_matrix(ground_truth, predictions)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    # Creating performance text\n",
        "    txt = \"Accuracy: {:.3f}%\".format(acc).center(30) + \"\\n\" \\\n",
        "        + f\"True positive: {tp}\".rjust(20)                  \\\n",
        "        + f\" | False positive: {fp}\".rjust(20) + \"\\n\"       \\\n",
        "        + f\"True negative: {tn}\".rjust(20)                  \\\n",
        "        + f\" | False negative: {fn}\".rjust(20)\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
        "                                  display_labels=[\"negative\", \"positive\"])\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.figtext(0.5, -0.2, txt, wrap=True, \n",
        "                horizontalalignment='center', fontsize=12);\n",
        "    \n",
        "    return disp, {'acc': acc, 'tn':tn, 'fp':fp, 'fn':fn, 'tp':tp, 'cm':cm}\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "def exhaustive_LFW_eval(dataset_root, backends=[], models=[], show_prog=True):\n",
        "    \"\"\"\n",
        "    Exhaustive evaluation of the LFW data set (or any subset with the same\n",
        "    structure). In this case, exhaustive means all the unique pair-wise\n",
        "    combination of all available backends and models. The following default\n",
        "    backends and models are used if customs lists are not provided:\n",
        "    \n",
        "        backends = [ \"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\"]\n",
        "        models   = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \n",
        "                    \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"Ensemble\"]\n",
        "    \n",
        "    Inputs:\n",
        "        1. dataset_root - full path of the LFW data set (or subset) root\n",
        "        2. models - list of face verification model(s) ([models=[]])\n",
        "        3. backends - list of face detector model(s) ([backends=[]])\n",
        "        4. show_prog - flag indicating if progress bars should be shown\n",
        "            ([show_prog=True])\n",
        "            \n",
        "    Outputs:\n",
        "        1. list of 'FR_performance' objects, one for each face recognition\n",
        "            system. See the docstring of FR_perfomance class for more\n",
        "            information about these objects.\n",
        "        2. gt - array of boolean values indicating if the specific file has a\n",
        "            match in the gallery or not\n",
        "    \"\"\"\n",
        "    if len(backends) == 0:\n",
        "        backends = [ \"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\"]\n",
        "            \n",
        "    if len(backends) == 0:\n",
        "        models   = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \\\n",
        "                    \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\", \"Ensemble\"]\n",
        "    \n",
        "    # This function implements a pair-wise combinatorial generator:\n",
        "    # list1 = [a, b, c], list2 = [1, 2] then pairs(list1, list2)\n",
        "    # is a generator that outputs: (a, 1), (a, 2), (b, 1), (b, 2)\n",
        "    # (c, 1), (c, 2)\n",
        "    def pairs(*lists):\n",
        "        for t in itertools.combinations(lists, 2):\n",
        "            for pair in itertools.product(*t):\n",
        "                yield pair\n",
        "    \n",
        "    all_perf_results = []\n",
        "    for i, pair in enumerate(pairs(models, backends[-2:])):   # skipping opencv, ssd, dlib because they fail to detect faces and break everything\n",
        "        print(f\"Face detector: {pair[1]}\\nFace verifier: {pair[0]}\\n\")\n",
        "        \n",
        "        output   = evaluate_FR_on_LFW(dataset_root,\n",
        "                                      model_name=pair[0], \n",
        "                                      detector_backend=pair[1],\n",
        "                                      show_prog=show_prog)\n",
        "        \n",
        "        print(\" \")\n",
        "        \n",
        "        # The ground truth is always the same (as the data set is\n",
        "        # unchanged) so just store it once\n",
        "        if i == 0:\n",
        "            gt = output[\"gt\"]\n",
        "        \n",
        "        # Create FR_performance object, then calculate performance\n",
        "        cur_perf = FR_performance(pair[1] + \"_plus_\" + pair[0], output)\n",
        "        cur_perf.calc_performance(gt)\n",
        "        \n",
        "        # Append the object to the all performance results list\n",
        "        all_perf_results.append(cur_perf)\n",
        "            \n",
        "    return all_perf_results, gt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the data set\n",
        "\n",
        "First, we download the Labelled Faces in the Wild (LFW) data set and create a subset of this data set. In this subset, we create a gallery (known faces) and a targets directory (unknown faces).\n",
        "\n",
        "This step is skipped if the data set has been downloaded and the subset data set (called LFW_sub) already exists."
      ],
      "metadata": {
        "id": "IfHyZgWLfdTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the base data set directory if needed\n",
        "if create_dir(DATASETS_DIR):\n",
        "  print(f\"{DATASETS_DIR} already exists! Continuing...\\n\")\n",
        "\n",
        "LFW_DIR = os.path.join(DATASETS_DIR, \"lfw\")\n",
        "\n",
        "# Download and extract LFW images\n",
        "if os.path.isdir(LFW_DIR):\n",
        "  print(f\"{LFW_DIR} already exists. Skipping LFW data set download...\")\n",
        "else:\n",
        "  print(\"  > Downloading LFW images:\")\n",
        "  DownloadExtract.download_and_extract(\n",
        "      \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\", DATASETS_DIR, verbose=1)\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "# Create LFW subset\n",
        "LFW_SUB_ROOT = os.path.join(DATASETS_DIR, \"LFW_sub\")\n",
        "create_sub_LFW(LFW_SUB_ROOT, LFW_DIR, p1_num=100, p2_num=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJSpK-DcZCo5",
        "outputId": "90c5421f-0974-4254-dee9-894ca664290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > Downloading LFW images:\n",
            "Downloading Started\n",
            "Downloading Completed\n",
            "Extracting ... done!\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Face Recognition\n",
        "\n",
        "We run the face recognition system on the LFW_sub data set. All images in 'targets' directory are compared against those in 'gallery' and the system determines if there is a match.\n",
        "\n",
        "The performance of the face recognition system is then displayed as a confusion matrix along with important metrics such as false positives, false negatives, etc.\n",
        "\n",
        "Note that the face detector and face verifier models can be chosen:\n",
        "  - Face detectors = BACKENDS:\n",
        "    - BACKENDS[0] = opencv\n",
        "    - BACKENDS[1] = ssd\n",
        "    - BACKENDS[2] = dlib\n",
        "    - BACKENDS[3] = mtcnn\n",
        "    - BACKENDS[4] = retinaface\n",
        "    - BACKENDS[5] = mediapipe\n",
        "\n",
        "  - Face verifiers = MODELS:\n",
        "    - MODELS[0] = VGG-Face\n",
        "    - MODELS[1] = Facenet\n",
        "    - MODELS[2] = Facenet512\n",
        "    - MODELS[3] = OpenFace\n",
        "    - MODELS[4] = DeepFace\n",
        "    - MODELS[5] = DeepID\n",
        "    - MODELS[6] = ArcFace\n",
        "    - MODELS[7] = Dlib\n",
        "\n",
        "Warning: 'mediapipe' face detector is currently bugged."
      ],
      "metadata": {
        "id": "YedqaR69f6GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_BACKEND  = BACKENDS[4]  # use this model as face detector\n",
        "USE_MODEL    = MODELS[1]    # use this model as face verifier\n",
        "\n",
        "# Runs the face recognition system\n",
        "output = evaluate_FR_on_LFW(LFW_SUB_ROOT, USE_MODEL, USE_BACKEND)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKqBSemUZC7o",
        "outputId": "02b1db7e-a1fe-453f-be3b-7899ca68ee7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "facenet_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\n",
            "To: /root/.deepface/weights/facenet_weights.h5\n",
            "100%|██████████| 92.2M/92.2M [00:01<00:00, 86.2MB/s]\n",
            "Finding representations:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            "  8%|▊         | 9.96M/119M [00:00<00:01, 98.5MB/s]\u001b[A\n",
            " 17%|█▋        | 19.9M/119M [00:00<00:01, 94.5MB/s]\u001b[A\n",
            " 25%|██▌       | 29.9M/119M [00:00<00:00, 89.9MB/s]\u001b[A\n",
            " 34%|███▍      | 40.4M/119M [00:00<00:00, 95.3MB/s]\u001b[A\n",
            " 42%|████▏     | 50.3M/119M [00:00<00:00, 92.9MB/s]\u001b[A\n",
            " 50%|█████     | 59.8M/119M [00:00<00:00, 83.2MB/s]\u001b[A\n",
            " 59%|█████▉    | 69.7M/119M [00:00<00:00, 87.7MB/s]\u001b[A\n",
            " 68%|██████▊   | 80.2M/119M [00:00<00:00, 87.0MB/s]\u001b[A\n",
            " 76%|███████▌  | 90.2M/119M [00:01<00:00, 90.1MB/s]\u001b[A\n",
            " 84%|████████▍ | 99.6M/119M [00:01<00:00, 89.3MB/s]\u001b[A\n",
            " 92%|█████████▏| 109M/119M [00:01<00:00, 87.1MB/s] \u001b[A\n",
            "100%|██████████| 119M/119M [00:01<00:00, 87.2MB/s]\n",
            "Finding representations: 100%|██████████| 100/100 [01:02<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representations stored in  /content/data_sets/LFW_sub/gallery / representations_facenet.pkl  file. Please delete this file when you add new identities in your database.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing: 100%|██████████| 543/543 [04:03<00:00,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "find function lasts  313.2137222290039  seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots performance results\n",
        "disp, perf = get_and_plot_performance(output[\"result\"], output[\"gt\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGW3kGfTZC9o",
        "outputId": "d20700f0-b197-443d-9b60-98db39250643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAFKCAYAAABVbDeXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debyUZf3/8debA+IuIm4girmkaGpJKm65tKgtWO7iVplZWWpaafkry/Rr5Terb6lRmrivqbhrLrmnmIiIoqQo4ooKgqIGfH5/XNfIzfHMnDmHc2bODO8nj/vBvd/XzD3nM9dc93V/bkUEZmZWO73qXQAzs8WNA6+ZWY058JqZ1ZgDr5lZjTnwmpnVmAOvmVmN9a53AXq6fiuuFKsNGlzvYlgHLNPXH+tG8txzU5g+fboWZR8ty68VMXdOVevGnNdujohdFuV4i8qf0HasNmgwo/5+e72LYR2wxUf617sI1gHbbDlskfcRc9+l7wb7VrXuu4/834BFPuAicuA1s8YnQItUaa4pB14zaw5qnEtWDrxm1hxc4zUzqyVBr5Z6F6JqDrxm1viEmxrMzGpLbmowM6s513jNzGrMNV4zsxpSY11ca5y6uZlZJepV3dDebqQlJT0o6VFJj0v6eZ6/tqR/SZos6VJJS+T5ffP05Lx8SHvHcOA1syagLgu8wHvAThGxKbAZsIukrYBfAadHxLrAm8DX8/pfB97M80/P61XkwGtmzaGXqhvaEcnsPNknDwHsBFyR548Gds/jI/I0efnOUuUGZwdeM2t8pX68XVPjRVKLpHHAq8CtwH+AGRExN6/yAjAojw8CpgLk5TOBlSrt3xfXzKw5VN+rYYCksYXpURExqrhCRMwDNpPUD7gK2KBrCpk48JpZE+hQr4bpEVFVLsqImCHpDmA40E9S71yrXQOYllebBgwGXpDUG1gBeL3Sft3UYGbNoet6Nayca7pIWgr4DPAEcAewZ17tYOCaPD4mT5OX3x4RUekYrvGaWeNTl94yvDowWlILqXJ6WURcJ2kicImkXwKPAGfn9c8Gzpc0GXgDaDcjuwOvmTWHLrplOCLGAx9vY/4zwBZtzH8X2Ksjx3DgNbPm4FuGzcxqqbFuGXbgNbPG53y8Zma1JgdeM7OacxuvmVmNucZrZlZjrvGamdVQgyVCd+A1s6bQTibGHsWB18wannDgNTOrLeWhQTjwmlkTkGu8Zma15sBrZlZjvXq5H6+ZWe24jdfMrLbkNl4zs9pz4DUzqzEHXjOzWhKolwOvmVlNucZrZlZDvrhmZlYHDrxmZrXWOHHXgdfMmoBc4zUzqznfMmxmVkONdnGtcb4izMwqUZVDe7uRBku6Q9JESY9LOjLPP1HSNEnj8rBbYZvjJU2WNEnS59o7hmu8Ztb4uraNdy5wTET8W9JywMOSbs3LTo+I0xY6tDQU2BfYCBgI/EPS+hExr9wBXOM1s6YgqaqhPRHxUkT8O4/PAp4ABlXYZARwSUS8FxHPApOBLSodw4HXzJpCVwXeVvscAnwc+FeedYSk8ZLOkbRinjcImFrY7AUqB2o3NSwurrrhfm687WGCYNedNucrn9+au+6fwPlX3MHUadP5w8mHsf46FT8rVidnXXwHo6++DyI4aPdt+Nb+O9a7SD1SB3I1DJA0tjA9KiJGfWh/0rLAlcBREfGWpDOBk4DI//8v8LXOlLVha7yS+kn6dmF6oKQr6lmmnmrK869w420P84dTDuOsX3+bf/37Kaa9/DpDBq/KT4/Zj49tuFa9i2hlTJz8IqOvvo/bRv+Auy86npvvmcAzU1+rd7F6nGpru7nGOz0ihhWGtoJuH1LQvTAi/g4QEa9ExLyImA/8hQXNCdOAwYXN18jzymrYwAv0Az4IvBHxYkTsWcfy9FjPT3uNDdZbgyX7LkFLSwubDB3Cvf+ayJprrMzggQPqXTyr4KkpLzNs4yEsveQS9O7dwjafWJdr7xhX72L1SF3V1KC00tnAExHx28L81QurfRmYkMfHAPtK6itpbWA94MFKx+i2wCtpiKQnJP0ld8m4RdJSktaRdJOkhyXdLWmDvP46kh6Q9JikX0qanecvK+k2Sf/Oy0bkQ5wKrJO7dfwmH29C3uYBSRsVynKnpGGSlsltMw9KeqSwr6Y2ZPCqTHjyOd6a9Q7vvvc+Dz3yFK+9/la9i2VV2HCdgdw/bjJvzJjNO+++z633Pc60V96sd7F6pC5s490GOBDYqVXXsV/nGDQe2BE4GiAiHgcuAyYCNwHfqdSjAbq/jXc9YL+I+Iaky4A9gK8Ch0fE05K2BM4AdgJ+D/w+Ii6WdHhhH+8CX85tLAOABySNAY4DNo6IzeCDRvCSS4G9gZ/lb6nVI2KspFOA2yPia5L6AQ9K+kdEvF0stKTDgMMAVh24Rte+I3Ww5hors/eXtuX4k0ezZN8l+MiQ1enVQLlLF2cfXXs1jjzoM3zlu39i6aWWYOP116Clge7Qqqku+khHxD1l9nZDhW1OBk6u9hjdHXifjYjS76KHgSHA1sDlhW+evvn/4cDuefwioNRXTsApkrYH5pOuFq7aznEvA24BfkYKwKW2388CX5J0bJ5eEliT1F3kA7nNZxTABhtvFlW8zh5vl502Z5edNgfgnItvZeX+K9S5RFatA0dszYEjtgbgF38aw8BV+tW5RD2QGuuW4e4u6XuF8XlAf2BGRGxWGDZsZx8jgZWBzXPt9hVSwCwrIqYBr0vaBNiHVAOGFMT3KBx7zYh4ouyOmsiMmbMBeHX6DO598Al23PZjdS6RVeu1N2YBMPXlN7jujkfZa5dhdS5RzyNAqm7oCWrdnewt4FlJe0XE5bkRe5OIeBR4gNQUcSnpLpCSFYBXI+K/knYESpfgZwHLVTjWpcAPgRUiYnyedzPwXUnfjYiQ9PGIeKTrXl7P9YvfXsKsWXNoaenFEV/7PMsusxT3PjiRM/52AzPfepv/96sLWGet1TjlJwfXu6jWykE/+itvznyb3r1b+M0P92aF5Zaud5F6oMbK1VCPfrwjgTMlnQD0AS4BHgWOAi6Q9BNSA/XMvP6FwLWSHgPGAk8CRMTrku7NF9RuBP7U6jhXkNqNTyrMOwn4HTBeUi/gWeALXf8Se57f/vzQD83bZouhbLPF0DqUxjrixr8cXe8iNIQGirvdF3gjYgqwcWG6eH/zLm1sMg3YKtdE9wU+mrebTmr/besY+7eaVTzeK7R6fRExB/hm9a/CzBqFa7ydsznwx9z8MINO3hFiZouhHtR+W40eE3gj4m5g03qXw8waj4CWlsaJvD0m8JqZLQo3NZiZ1ZKbGszMaiv1422cyOvAa2ZNwP14zcxqroHirgOvmTUB0VCJnxx4zazhuY3XzKwOGijuOvCaWXNwjdfMrMYaKO468JpZ45MvrpmZ1Zr78ZqZ1VwDxV0HXjNrDq7xmpnVkpPkmJnVlm+gMDOrA/dqMDOrMdd4zcxqqcHaeHvVuwBmZotKuR9vNUO7+5IGS7pD0kRJj0s6Ms/vL+lWSU/n/1fM8yXpD5ImSxov6RPtHcOB18yaglTdUIW5wDERMRTYCviOpKHAccBtEbEecFueBtgVWC8PhwFntncAB14zawotvVTV0J6IeCki/p3HZwFPAIOAEcDovNpoYPc8PgI4L5IHgH6SVq90DLfxmlnDS7XZrm/klTQE+DjwL2DViHgpL3oZWDWPDwKmFjZ7Ic97iTIceM2sKXSgN9kASWML06MiYlTrlSQtC1wJHBURbxUDe0SEpOhsWcsGXkn/B5TdcUR8r7MHNTPrah2o8U6PiGHt7KsPKeheGBF/z7NfkbR6RLyUmxJezfOnAYMLm6+R55VVqcY7tsIyM7MepataGpQi+NnAExHx28KiMcDBwKn5/2sK84+QdAmwJTCz0CTRprKBNyJGF6clLR0R73T4VZiZdTORupR1kW2AA4HHJI3L835MCriXSfo68Bywd152A7AbMBl4B/hqewdot41X0nBS9F8WWFPSpsA3I+LbHXstZmbdRNX1WKhGRNwDZaP4zm2sH8B3OnKMarqT/Q74HPB6PsijwPYdOYiZWXfrwn683a6qXg0RMbVVw/W87imOmVnHCejVU6JqFaoJvFMlbQ1EvtJ3JKlDsZlZj9FAcbeqpobDSe0Xg4AXgc3oYHuGmVl366pcDbXQbo03IqYDI2tQFjOzTulJ7bfVaLfGK+kjkq6V9JqkVyVdI+kjtSicmVm1WqSqhp6gmqaGi4DLgNWBgcDlwMXdWSgzs45qpKaGagLv0hFxfkTMzcMFwJLdXTAzs2qlXg3VDT1BpVwN/fPojZKOAy4h5W7Yh3SnhplZz9CDarPVqHRx7WFSoC29mm8WlgVwfHcVysysoxoo7lbM1bB2LQtiZtZZgi67ZbgWqrpzTdLGwFAKbbsRcV53FcrMrKOapakBAEk/A3YgBd4bSM8Xugdw4DWzHqNxwm51vRr2JGXkeTkivgpsCqzQraUyM+sAKeVqqGboCappapgTEfMlzZW0PCnr+uD2NjIzq6UeElOrUk3gHSupH/AXUk+H2cD93VoqM7MOaqo23kLC87Mk3QQsHxHju7dYZmbVE12XCL0WKt1A8YlKy0rPnTczq7sGS5JTqcb7vxWWBbBTF5elR3p//nyen+VHzTWSz33yp/UugnXAe5Oe75L9NEVTQ0TsWMuCmJktimq6aPUUVd1AYWbWk4kmqfGamTWSBrq25sBrZo1PaqxcDdU8gUKSDpD00zy9pqQtur9oZmbVa6R8vNW0R58BDAf2y9OzgD91W4nMzDqh9Ny19oaeoJqmhi0j4hOSHgGIiDclLdHN5TIzq1p6AkUPiapVqKbG+19JLaS+u0haGZjfraUyM+ugXlUO7ZF0Tn6w74TCvBMlTZM0Lg+7FZYdL2mypEmSPldNWaup8f4BuApYRdLJpGxlJ1SzczOzWpC69Jbhc4E/8uHUt6dHxGmtjjsU2BfYiPQw4H9IWj8i5lU6QDW5Gi6U9DApNaSA3SPiiapfgplZDXRVS0NE3CVpSJWrjwAuiYj3gGclTQa2oJ1EYtX0algTeAe4FhgDvJ3nmZn1GB3o1TBA0tjCcFiVhzhC0vjcFLFinjcImFpY54U8r6JqmhquZ8FDL5cE1gYmkarWZmZ118GLa9MjYlgHD3EmcBIpFp5EymXztQ7u4wPVNDV8rDids5Z9u8zqZmZ10Z2dGiLilQXH0V+A6/LkNBZ+MMQaeV5FHc4rkdNBbtnR7czMuk2VzQydvf4mafXC5JeBUo+HMcC+kvpKWhtYD3iwvf1V87DL7xcmewGfAF6susRmZt1MQEsXVXklXUx6wO8ASS8APwN2kLQZqalhCvBNgIh4XNJlwERgLvCd9no0QHVtvMsVxueS2nyvrP5lmJl1v67qTRYR+7Ux++wK658MnNyRY1QMvPnGieUi4tiO7NTMrNaaIi2kpN4RMVfSNrUskJlZR6VeDfUuRfUq1XgfJLXnjpM0BrgceLu0MCL+3s1lMzOrTg9KgFONatp4lwReJz1jrdSfNwAHXjPrMRopSU6lwLtK7tEwgQUBtyS6tVRmZh0goKWBHrpWKfC2AMuycMAtceA1sx5E9GozVPVMlQLvSxHxi5qVxMysk9LDLutdiupVCrwN9DLMbLHWgx7rU41KgXfnmpXCzGwRNcXFtYh4o5YFMTPrrHRxrQkCr5lZI2mgCq8Dr5k1PtGJVIt15MBrZo1PTZKrwcyskTRO2HXgNbMm0MFH/9SdA6+ZNYUG6tTgwGtmzUBu4zUzqyX3ajAzqwPXeM3Maqxxwq4Dr5k1A/fjNTOrra58vHstOPCaWVNonLDrwGtmTaKBKrwOvGbW+FJ3ssaJvI3U9c3MrCypuqH9/egcSa9KmlCY11/SrZKezv+vmOdL0h8kTZY0XtInqimrA6+ZNQHRS9UNVTgX2KXVvOOA2yJiPeC2PA2wK7BeHg4DzqzmAA68ZtbwSk0N1QztiYi7gNZP4BkBjM7jo4HdC/PPi+QBoJ+k1ds7hgOvmTW+KpsZFuEC3KoR8VIefxlYNY8PAqYW1nshz6vIF9fMrCl0IKgOkDS2MD0qIkZVu3FEhKToSNlac+A1s6ag6ns1TI+IYR3c/SuSVo+Il3JTwqt5/jRgcGG9NfK8itzUYGYNLyVCr27opDHAwXn8YOCawvyDcu+GrYCZhSaJslzjNbOm0FVPoJB0MbADqUniBeBnwKnAZZK+DjwH7J1XvwHYDZgMvAN8tZpjOPA2qXP/dj3jx/+H5ZZbmp//4lAALr/8dsY/OpmWlhZWXqUfX/3q51l66SWZPXsOZ515FVOmvMTWW3+M/Ud+ts6lX/z0XaI31486ir59etPSu4Uxtz3CqaNuYNRJB7PZhmsyd+48Hn78OY4+5WLmzpvPXrsM48iDPoMkZr/zLseceikTnm73F25T60BTQ0URsV+ZRTu3sW4A3+noMRquqUHS4ZIOyuOHSBpYWPZXSUPrV7qeY+ttPsaRR+290LyhQ9fmxJ8fyok//zqrrtqfG264H4A+fVoYsft27LnXTvUoqgHvvT+XEd/6A9uNPJXt9/8fdh4+lGEbD+HyGx9iiz1PYut9T2Gpvn04aPetAXjuxdf5/Dd/xzb7ncJvzr6J039cLlYsHmrQ1NClGi7wRsRZEXFenjwEGFhYdmhETKxLwXqY9ddfk2WWWXKheRtttDYtLemUf+QjA3nzzVkA9O27BOutN5g+fVpqXk5b4O057wPQp3cLfXq3EBHcet+Cj/PDjz/HwFVWBODB8c8yc9YcAB567FkGrtKv9gXuUVT1v56gpoFX0hBJT0q6UNITkq6QtLSknSU9IumxfLte37z+qZIm5lvxTsvzTpR0rKQ9gWHAhZLGSVpK0p2ShuVa8W8Kxz1E0h/z+AGSHszb/FnSYhlt7r1nPB/b+CP1LoYV9Ool7rrwOJ665VTu/NeTPPz4cx8s693Si31224Lb7v9wveLAEVvzj/sW8/pG9/fj7VL1qPF+FDgjIjYE3gK+T7pFb5+I+Bip3flbklYCvgxsFBGbAL8s7iQirgDGAiMjYrOImFNYfGXetmQf4BJJG+bxbSJiM2AeMLIbXmOPdv1199GrpRdbbrVRvYtiBfPnB9uPPJWNPn8Cn9hoLTZcZ8ENUKcdtw/3PTKZ+8f9Z6Fttt18PQ740nBO/OM1rXe3WCnl461m6AnqEXinRsS9efwCUoP1sxHxVJ43GtgemAm8C5wt6SukK4ZViYjXgGckbZUD+AbAvflYmwMPSRqXpz9U7ZN0mKSxksa+9WbrOwcb2733jmf8+MkceuiXGipj/+LkrdlzuPvhp9h5eLpc8cNDd2VAv2X5yel/X2i9jdYdyB9O2J+Rx47izZlv16OoPYqqHHqCegTe1nd8zGhzpYi5wBbAFcAXgJs6eJxLSF0+9gCuylcfBYzONeTNIuKjEXFiG8ceFRHDImLY8iv27+Bhe64JE57h5pv+xRHf3ZO+ffvUuzhWsFK/ZVl+2aUAWLJvH3bcYgOenvIKB44Yzs7DN+TQE84lfYSTNVZdkfN+/Q0O/9l5/Of5V8vtdvHSQJG3Ht3J1pQ0PCLuB/YnNRd8U9K6ETEZOBD4p6RlgaUj4gZJ9wLPtLGvWcByZY5zFfAT4OPAj/K824BrJJ0eEa9K6g8sFxHPldlHwxo16hqemvQ8s2fP4Qc/+BNf+tK23HjD/cydO4/f/vYSIF1gO/DAlITpuB+dwZw57zNv3jweGfc0Rx+9DwMHDqjnS1isrDZgec448UBaevWiVy9x1T/+zc33TOC1+3/P1Jff4JZzjgHg2jvG8Zu/3sQPDt2V/issw2k/2geAuXPns9PBv67nS6i7nnLhrBr1CLyTgO9IOgeYCHwPeAC4XFJv4CHgLKA/KUguSfqe+n4b+zoXOEvSHGB4cUFEvCnpCWBoRDyY502UdAJwi6RewH9JffCaLvAedtiID83bbrtNy65/6q++3Z3FsXY8PvlFPnXArz40f+XhR7a5/pEnX8SRJ1/U3cVqKI3UclaPwDs3Ig5oNe82Us206CVSU8NCik0DEXEl6UJayQ6t1v1CG9tfClzaoRKbWY/XQHHXd66ZWeMTfrx7WRExBdi4lsc0s8VAD+qjWw3XeM2sKTRQ3HXgNbMm0UCR14HXzJpAz8nDUA0HXjNrCm7jNTOrodSrod6lqJ4Dr5k1BTc1mJnVmGu8ZmY11kBx14HXzJpAD8o8Vg0HXjNreOmZa40TeR14zawpNE7YdeA1s2bRQJHXgdfMmoK7k5mZ1VgDNfE68JpZc2iguOvAa2aNr6sToUuaQnqm4zzSU3OG5Wc0XgoMAaYAe0fEm53Zfz2eMmxm1rVyIvRqhg7YMT+NfFiePg64LSLWIz2u7LjOFteB18yaQg2e7j4CGJ3HRwO7d3ZHDrxm1hy6NvIG6WnkD0s6LM9bNSJeyuMvA6t2tqhu4zWzJtChROgDJI0tTI+KiFGt1tk2IqZJWgW4VdKTxYUREZKis6V14DWzptCB9tvphXbbNkXEtPz/q5KuArYAXpG0ekS8JGl14NXOltVNDWbW8EqJ0Lvi4pqkZSQtVxoHPgtMAMYAB+fVDgau6Wx5XeM1s6bQhXeurQpclbun9QYuioibJD0EXCbp68BzwN6dPYADr5k1ha7qxhsRzwCbtjH/dWDnrjiGA6+ZNQXfuWZmVksdvzmirhx4zazhdfUtw93NgdfMmkLjhF0HXjNrEg1U4XXgNbPm4EToZma11jhx14HXzJpDA8VdB14za3ySH+9uZlZ7jRN3HXjNrDk0UNx14DWz5tBALQ0OvGbWDDqUCL3uHHjNrOGV8vE2CgdeM2sKDrxmZjXmpgYzs1pyWkgzs9rq2JPb68+B18yaQwNFXgdeM2sKvmXYzKzGGifsOvCaWbNooMjrwGtmTaGRupMpIupdhh5N0mvAc/UuRzcYAEyvdyGsQ5r1nK0VESsvyg4k3UR6f6oxPSJ2WZTjLSoH3sWUpLERMaze5bDq+Zw1j171LoCZ2eLGgdfMrMYceBdfo+pdAOswn7Mm4TZeM7Mac43XzKzGHHjNzGrMgdeQ1E/StwvTAyVdUc8y2QKSDpd0UB4/RNLAwrK/Shpav9JZZ7iN15A0BLguIjauc1GsHZLuBI6NiLH1Lot1nmu8DUDSEElPSPqLpMcl3SJpKUnrSLpJ0sOS7pa0QV5/HUkPSHpM0i8lzc7zl5V0m6R/52Uj8iFOBdaRNE7Sb/LxJuRtHpC0UaEsd0oaJmkZSedIelDSI4V9WUF+L5+UdGE+h1dIWlrSzvl9eyy/j33z+qdKmihpvKTT8rwTJR0raU9gGHBhPldLFc7H4ZJ+UzjuIZL+mMcPyOdpnKQ/S2qpx3thBRHhoYcPwBBgLrBZnr4MOAC4DVgvz9sSuD2PXwfsl8cPB2bn8d7A8nl8ADCZlFpkCDCh1fEm5PGjgZ/n8dWBSXn8FOCAPN4PeApYpt7vVU8b8nsZwDZ5+hzgBGAqsH6edx5wFLASMIkFv0T75f9PJNVyAe4EhhX2fycpGK8MTC7MvxHYFtgQuBbok+efARxU7/dlcR9c420cz0bEuDz+MOkPemvgcknjgD+TAiPAcODyPH5RYR8CTpE0HvgHMAhYtZ3jXgbsmcf3Bkptv58FjsvHvhNYElizw69q8TA1Iu7N4xcAO5PO51N53mhge2Am8C5wtqSvAO9Ue4CIeA14RtJWklYCNgDuzcfaHHgon6udgY90wWuyReDsZI3jvcL4PFLAnBERm3VgHyNJNaPNI+K/kqaQAmZZETFN0uuSNgH2IdWgIQXxPSJiUgeOv7hqfSFlBql2u/BKEXMlbUEKjnsCRwA7deA4l5C+HJ8EroqIkCRgdEQc36mSW7dwjbdxvQU8K2kvACWb5mUPAHvk8X0L26wAvJqD7o7AWnn+LGC5Cse6FPghsEJEjM/zbga+m/+wkfTxRX1BTWxNScPz+P7AWGCIpHXzvAOBf0palvQe30Bq4tn0w7uqeK6uAkYA+5GCMKTmqD0lrQIgqb+ktcpsbzXiwNvYRgJfl/Qo8Djpjw5Se+H3c5PCuqSfsAAXAsMkPQYcRKoZERGvA/dKmlC8QFNwBSmAX1aYdxLQBxgv6fE8bW2bBHxH0hPAisDpwFdJzUSPAfOBs0gB9bp83u4Bvt/Gvs4FzipdXCsuiIg3gSdIaRYfzPMmktqUb8n7vZUFTVJWJ+5O1oQkLQ3MyT819yVdaHOvgzpwVz1ri9t4m9PmwB9zM8AM4Gt1Lo+ZFbjGa2ZWY27jNTOrMQdeM7Mac+A1M6sxB15bJJLm5a5NEyRdnntUdHZf5+Z8BO1m3ZK0g6StO3GMKZI+9DTacvNbrTO7g8c6UdKxHS2jNT8HXltUcyJis9xd6n0W3NkGgKRO9ZyJiENzH9RydiDdMm3WcBx4rSvdDayba6N3SxoDTJTUkrOePZSzbn0TPrjb7o+SJkn6B7BKaUelrFt5fBeljGqPKmVXG0IK8Efn2vZ2klaWdGU+xkOStsnbrqSUze1xSX8l3epckaSrlTK+PS7psFbLTs/zb5O0cp7XZpY4s3Lcj9e6RK7Z7grclGd9Atg4Ip7NwWtmRHxSKf3hvZJuAT4OfBQYSso9MZGUvau435WBvwDb5331j4g3JJ1FyrpWSp14EXB6RNwjaU3SLc0bAj8D7omIX0j6PPD1Kl7O1/IxliIll7ky3923DDA2Io6W9NO87yNID6E8PCKelrQlKQNYR3Is2GLGgdcW1VI56xWkGu/ZpCaAByPi2Tz/s8AmpfZbUs6I9UgZuS6OiHnAi5Jub2P/WwF3lfYVEW+UKcengaE5dQTA8jn3wfbAV/K210t6s4rX9D1JX87jg3NZXyfd2ntpnn8B8Pd8jFKWuNL2fas4hi3GHHhtUc1pnSEtB6C3i7OA70bEza3W260Ly9EL2Coi3m2jLFWTtAMpiA+PiHeUnvhQLoNb5ON2NEucLebcxmu1cDPwLUl9ACStL2kZ4C5gn9wGvDqwYxvbPgBsL2ntvG3/PL91lq5bgO+WJiSVAuFdpIxgSNqVlKSmkhWAN3PQ3YBU4y7pxYLcxPuTmjAqZZg/LM4AABbBSURBVIkza5MDr9XCX0ntt/9WeqTQn0m/tq4Cns7LzgPub71hTvB9GOln/aMs+Kl/LfDl0sU14HukzGvjJU1kQe+Kn5MC9+OkJofn2ynrTUDvnEnsVFLgL3kb2CK/hp2AX+T55bLEmbXJuRrMzGrMNV4zsxpz4DUzqzEHXjOzGnPgNTOrMQdeM7Mac+A1M6sxB14zsxpz4DUzqzEHXjOzGnPgNTOrMQdeM7Mac+A1M6sxB14zsxpz4DUzqzEHXjOzGnPgNTOrMQdeM7Mac+A1M6sxB14zsxpz4DUzqzEHXjOzGnPgNTOrMQdeM7Mac+A1M6sxB14zsxpz4DUzqzEH3sWYpBMlhaQt612WWpA0u9UwT9L/FZYvLekMSdMlzZR0V4V99Zd0laS3JT0naf/Csh0kzW91rIMLyzeUdHs+xmRJXy4sGyzpAUlvSPrfVse8UdKwrntHrF4ceBdTkgQcBLyR/6/lsXvX8nglEbFsaQBWA+YAlxdWGQX0BzbM/x9dYXd/At4HVgVGAmdK2qiw/MXi8SJiNHzw2q8BrsvHOAy4QNL6ebvjgdHA2sDupUAraR/g2YgY2/l3wHoKB97F13bA6sD3gH0lLVFaIGkpSf+ba3IzJd0jaam8bFtJ90maIWmqpEPy/DslHVrYxyGS7ilMh6TvSHoaeDrP+33ex1uSHpa0XWH9Fkk/lvQfSbPy8sGS/tRGTXCMpEpBsi17AK8Cd+d9bAB8CTgsIl6LiHkR8XBbG0paJm///yJidkTcA4wBDqziuBsAA4HT8zFuB+4tbLs2cHtEzAQeAj4iaXngOODHHXyN1kM58C6+DgauBS7L018sLDsN2BzYmlQr+yEwX9JawI3A/wErA5sB4zpwzN2BLYGhefqhvI/+wEXA5ZKWzMu+D+wH7AYsD3wNeIdUG9xPUi8ASQOATwMXSTpO0nVVluVg4LyIiDy9BfAc8PPc1PCYpD3KbLs+MDcinirMexQo1nhXkfSKpGclnZ6DdTkCNs7jE4DPSOpHOgePAycBv4uIGVW+NuvpIsLDYjYASwNvAbvn6T8D1+TxXqSf4Ju2sd3xwFVl9nkncGhh+hDgnsJ0ADu1U643S8cFJgEjyqz3BPCZPH4EcEMHX/9awDxg7cK8H+cynggsAXwKmA1s2Mb22wEvt5r3DeDOPL4a6culF6kGexfw57ysD/AM6cusD/BZUpPFzXl5f+BSUiA/Gvg4cAcLvpzuAo6o92fIw6INrvEunr4MzAVuyNMXArtKWhkYACwJ/KeN7QaXmV+tqcUJScdKeiI3Z8wAVsjHb+9Yo4ED8vgBwPkdLMeBpC+FZwvz5gD/BX4ZEe9HxD9JAe+zbWw/m1QLL1oemAUQES9HxMSImJ+P8UNS0wQR8V9Szf/zwMvAMaRfHS/k5W9ExD4RsSnwe9Kvi++SmhomkGr3h0vasIOv2XoQB97F08HAssDzkl4mXWDqA+wPTAfeBdZpY7upZeYDvE2qSZes1sY6pZ/15PbcHwJ7AytGRD9gJulnd3vHugAYIWlT0oWwq8usV85BpOBdNL5SeVt5Cugtab3CvE1JzQJtCQp/axExPiI+FRErRcTngI8AD7ax3WHAAxExAfgYMDYi3gcey9PWqOpd5fZQ2wEYRPqZ/VlScCwNpwIP53X+BNxGugjUAgwH+gJrkmp1ewO9gZWAzfI2J5OaG5YG1iVdQGvd1LBuYXo34MV87CWAn+ZyfTov/wEpGK5HCsabACsVtr81Lz+ng69/a9KXxHKt5vcBJgP/L7+2bfJr3aDMfi4BLgaWyevOBDbKy3YkNWeIVHO/A/hbYdtNSL8qlgaOBZ4F+rba/yqkALtsnj4D+B/SF+bTwLB6f5Y8dH6oewE81PiEp5+sD7cxfyDpp/bGwFLA74BpOaDcBSyV19sO+BepjXgqcHCePwC4JQere0ltpZUCbwtwTt7PS6Ta75RC4G0BTshBaRbpQtwahe0PyPvcsTDvx8CN7bz+PwPnl1m2EXB/DswTgS+X2zepzfXqvO7zwP6FZd/P7907+T36QzHQA78htWfPJl2sXLeNspwH7FWYHpzf9zeB39b7c+Rh0Qblk2rWUCRtT2pyWCv8IbYG4zZeaziS+gBHAn910LVG5MBrDSVfzZ9Buvnjd3UujlmnuKnBzKzGXOM1M6sxB177gKSRkm6psHw7SZNqWabulnNKnNvF+1wob0VPlXNh/LXC8oqfB+s8B95FkANRKe3f2zkRTDEV4Jr1LmNHRMSFEfHBnVr59axbWH53RHy0u8shaV9Jk/Idba9KGp0TxSCpr6SzcwKfWZLGSdq1sO1Wkm7NaRVfk3S5pNUXoSxTJM1pdV4HdsXrrLeIOCUiDgWQNCSf796F5Qt9HrqLpH75HL+ahxO7+5j15sC7CHIgKqUZLCVI6RcLUgE+X1pXdUqF2KDuBbaJiBVId3X1Bn6Zl/Um9Y39FOkW4xOAyyQNyctXJKV3HEK6iWEW8LdFLM8XY+EUjy8u4v5sYaeTbiYZQkpWdKCkr9a1RN3MgbebKCUZv0LSBZLeAg6RdK6kXxbW2UHSC4XpgZKuzDW1ZyV9r8L+z5V0Vq7dzZL0z5w9rLR8a0kP5VrjQ5K2Liw7RNIzebtnJY0szL8nj5eSgD+aa3n7FMsr6UeSrmhVpt9L+kMeXyHXTF+SNE3SLyW1VPPeRcTUiJhemDWPdDccEfF2RJwYEVMi5UK4jnSTxeZ5+Y0RcXlEvBUR7wB/JN1Z1mUkrSjpunye3szja5RZd918bmYqZT27tLBsg0LtfJKkvSsc805J/yPpQaU0mtdI6l9Y/iVJjyul67xThVwO+VxNy+d7kqSd8/wTJV2QVyud7xn5fA9v9Xk4U9Jprcp0jaTv5/GqP7tt+CLw64h4JyKmAGeTstE1LQfe7jUCuALoR0pEU5ZSmsNrSVmpBgE7A0dJ+lyFzUaSUgYOIKVnvDDvqz9wPemOqZWA3wLXS1pJKT3hH4BdI2I50i20H0rtGBHb59FNcy3v0larXALsJmm5fMwW0q3EF+Xl55IS8axLyrD1WaD0s3bNHCDKNsUo5f2dSaqx7kGZrmOSViWlaSyXJ2H7Css6qxepFr0W6TbqOaQA35aTSHf0rQisQUp6U8rpeyvp/VoF2Bc4Q9LQMvuBlGPia6SudHNJ5xGlJOoXA0eR0nXeAFwraQlJHyVlcPtkPt+fI90h2FrpfJd+sd3favnFwD6SlI+5IumcXtLeZzefy/ZSWqrV+MblVmwGDrzd6/6IuDrXzOa0s+4ngZUj4heRsmM9A/yF9AdZzvURcVdEvAf8BBguaTAp89XTEXF+RMyNiIuBJ1mQc3c+sLGkpSLipYjocGCKiOeAf5MynQHsBLwTEQ/kYLgbcFSuob5K+jm5b972+YjoV2yKaWP/9+SmhjVIt9hOab2O0o0UFwKjI+LJNpZvQsoB8YOOvr5Wrs5fFDMkXR0Rr0fElbmGNouUp+JTZbb9LylAD4yIdyMlTQf4AjAlIv6Wz9EjwJXAXhXKcX5ETIiIt0k5JfbOX3j7kD4Lt0bKfnYa6bbvrUm/FvoCQyX1yb8UOpNh7m7SLdqlZPV7kj7fL9LOZzefy34V9n0TcJyk5ZSuKXyNhRMuNR0H3u41tf1VPrAWMLDwBz6DlB9g1Wr2HxGzSY/xGZiH51qt+xwwKP/R7gMcDrwk6Xqlpy90xkWkZOWQMpuVartrkZLOvFR4LX8m1ew6JCKmkf4wLynOz7Ws80m5bI9ovV3+A74RODIi7u7ocVvZPX9R9IuI3ZWezfZnpQt8b5F+pvcr05TyQ1IN7sHcFFD6Cb0WsGWr8z2StrO6lRQ/T8+R3uMBtDrfETE/rzsoIiaTasInAq9KukSduDiY7xC8hIXPd+lXXGc+u0XfI/1qeJr0WKSLyWkym5UDb/dqfXdKpdSJU0nP1OpXGJaLiN0q7H9waUTSsqTELS/mYa1W665JStxCRNwcEZ8h/WR9klQ76YzLgR1y++aXWRB4pwLvAQMKr2X5iNio3I7a0ZtCisj8c/ds0h/2HrmWR2H5WsA/gJMioqO5eqtxDPBRYMuIWJ4FP9PVesVIuXm/EREDgW+SmhPWJb1H/2x1vpeNiG9VOO7gwviapNr0dFqd7/z+DGbB+b4oIrbN6wTwqzb2Xc2dVBcDe+b3d0tSDR0699ldcOCUg3hkRKyWPyO9aDtNZtNw4K2tcaR20f6SViPVREoeBGblCyFLKT1zbGNJn6ywv91y+9kSpLbEByJiKqmNb31J+0vqrfSgxKHAdZJWlTQitzG+R8qQNb/M/l8h9SpoU0S8RkoF+TfSH94Tef5LpHbN/5W0vKRektaRVO7n+EKU+o+umcfXIv2Uv62wypmkPLxfbN2EI2kQcDvwx4g4q5rjdcJypBrajNye/rNyK0raSwsuvL1JCnDzSQ+7XF/SgZL65OGTqpzg/ABJQyUtDfwCuCIi5pESqX9e0s65+eUY0rm9T9JHJe0kqS8pz/Ic2j7fr+X5lc73I6RA/1fSEzNK7bad+ewW36N18vWHFqWugYexoBdLU3Lgra3zSRcgppAC0wcXrPIf0BdIzyB7lgUf8BUq7O8i0h/9G6Sr+gfkfb2e93UM8Drp5+4Xck+BXqS0hS/m7T4FlKtlnQiMzj8fy11xv4j8zLNW8w8i5dmdSAo4V5Bq2KWLa5X6OQ8lBY23SV3LJpEerVMKxN8kvU8va0Hf2pF520NJwePEwrLZZY7TWb8jtaFOBx4gNYWU80ngX7kMY0hNH8/ktuHPktpBXyQ9jeJXpPbYcs4nXbR8mZTP93sAETGJdO7/L5fpi6Qvpffz/k7N818mNfcc33rHuQfIycC9+XxvVaYMHzrf7X12lfu7V3hdm5NyD88i5Rwe2ZnrDo3EuRoalNLdVi9ExAn1LksjU3pK8g4RcUidi1KRpDuBCyKi7J1m1jhc4zUzqzHfTWWLu3GkNJNmNeOmBjOzGnNTg5lZjTnwWrtyx/8d6l2OjlDKZXFIF+9zoWxtzaTQ06SqfBq2aBx4K8j9SUtdkuZImt+NXZR6BLVK5AMQERtFxJ01OPYXJU3I7+99KuQtyP1Cb1ZKNLNI7WNakAKxmOrx0UV/BY1DKd3lp0vT+TbuZXPXsO487uqSxkh6MZ+DIa2WnybpaaWEPk9KOqjV8lFKiX7md/UXay058FYQKR9pKe3jrsCLUUgPWFzXNYVFI2k90i2oh5OSCl0LjNGCdJr/Jd0o8PUuPGwxheemXbhfK28+qd/zHmWWv03qh7wCcDDwexUy65H6wX+blCekcUUPeMZ8IwzADqR+s6Xpc0l3UN1A+rB8mnQX16GFdQ4B7ilMb0DKSPUG6aaAvSsc707S3Wj3kjqW30K6Bbe0fCvgPtIV+UdJfVFLy9Ym5Q+YRbp19k+kPqCl5ZeTOtPPzOttlOcfRgpw75PuaLs2z5+SX99A0p1P/Qv7+jipw3yfPP014AnSTRM3kx6/Xs37ewQp0Utpulc+1s6t1luXnDqgnf2dCxxSZtkQ0h1kvVvN3wK4P7+nL5Eyji1RWB7Aunl8N9LNIbNIt+YeW1jvCyzoLXEfsEmFcgbpy+bpvP6fyBe923s/STdgTMrn8Qzgn6XPH+kW69tJN9BMJ32p9cvLzicFwDn5PP+w+J6QcnmMbVXOo4ExebwvKRHP86S7G88Clurg31PvfLwh7aw3Bjimjfn3lDu/jTC4xrto9ifd7bMc6YNQljqXBnB/4Kt5/SWAY/O+BpHSPv6SlJ/hWOBKSSvn7S4i3ca5EunuswNb7fdGYL2833+Tk51ExKg8/utItcAvFjeKlInqfhaurexPunX1v5JGkJKjfIWUnvBu0v39pffgOknHVXi9rVMD1jo94DxSgBkADCelN/x2mXXPBr4ZKdXixqQgh6SPA+eQ7q5biZQcaEy+ZbecL5DucNuElFqzlE6x7PspaQDpbsDj83EmkbKRlYh0F9hA0u3Vg0mfBSLiQFLQLCV4/3Wr8lwLfDT/CikpJkE6lZSKczPSF+EgUhY4ctlmSNq2wuutiqSlSO9L893FVu/I3ygDbdd4z2u1zp2UqfGSahF3t1r/z8DPyhzvTuCEwvS3gZvy+I9IKQKL699M+mm2JilX69KFZRdQqPG22q4fqeaxQuF1/bLVOlOAT+fxQ4Hb87hICVK2z9M3Al8vbNcLeIcqar2kXwNv5/d5CVLaw/nA8a3W68oa74zCcGwb6x0FXFWYLtZ4nycF1+VbbXMmKTlPcd4k4FNlyhLAtoXpy4Dj2ns/Sbdk319YVjoXh5Y5zu7AI22d01bvSe/CZ+aneXw9Us1+6Xyct4F1CtsOJ+Xq6MjfU7s1XmA0qVlCbSxzjXcx1tG0jx1NA/hyYfwdoNSuvBawV6t9bUvKhTAQeCPSvfcfKmdORHKqpP8opTSckhcNqPJ1XEnK+7s6KSvXfFJNrFSu3xfK9AbpD3VQezuNlE/3YNLP+5dyeSbSvekBi9nTTpO0fq6Vv5zfm1Mo/77sQWpueE7pCRPD8/y1gGNanZvBpPNSTqXzXO79HMjCaUGDwnullAzpEqUnT7xFCqTVnmP4cMrPq/NnamVSAH64UK6b8vwuI+k3pF8Se+fX1lR859qi6Wjax39GSse4qKaSarzfaL0gJ5HpL2npQvAtphPcn/RkjE+Tgu4KpPbD0s/8ih/yiHhT6cmz+5B+wl5S+MOYCpwcERWftlFh31eQfj4jqR/pQtpDndlXJ50JPALsFxGzJB1FSvj9IRHxEDBCKRvYEaSa6mAWvAcnd0F5yr6fuRlgjcK0itOkL40APhYRb0janYWfktFeMLsVWFnSZqQAfHSeP53UNrxRpFzJXU7Sz0kXsz8VEW91xzHqzTXerjUO+IpSoux1WfgKfGfSAJZzAfBFSZ/LNdgllZ6HtkakJ0OMJWXnWiLXxIpttcuRUga+TvqSOKXVviumgswuIv3U3ZOFs5KdBRwvaSP44LlrlZ6osBBJm+fXszLpgZVjck0YJUuSmiHIr7lSu2lnLAe8BcxWSg7fZta2/L6OlLRCpFzAb7Eg1eJfgMMlbZnLvIykzys/IqmDKr2f1wMfk7R77vnxHRb+ol+OdOFsZr4m0PopHO2l/Pwv6SLsb0jXEW7N8+fn13i6pFVyuQap8iOqFpLPY+nc9c3TpWXHkyoHn46UZa/1tkvk9QX0yZ+DhotjDVfgHu50Uo+AV0jtUx/UVKJzaQDbFCnnbunCy2ukmtEPWHA+R5La3V4nXYC7lBRsAc4jPa1gGumn/AOtdn826TExMyRdXaYIY0jtfi9HxAf9XyPiqvyaLsk/byeQai4ASLpR0o8rvLTfk9pbJ5Fq4cUa/VqkmlbpQsucvF5XOpb0Rz+LFFxaP2eu6EBgSn6dh5PecyJiLKncfyS9hsmktv4Oq/R+RkrxuRfwa9J5Hkr6wi2d558DnyD1eLge+Hur3f8PcEI+z8eWKUIpBeTlETG3MP9H+XU9kMv1D1JieACU+kVvR3ml3hSQEvEXcyqfQrpOMVkL+lgXPzO35PW3Jn05z2FBIvqG4VwNiwGlJ9s+GRFlE3Y3G6W0mXdGxLl1LkpN5FrfC6RctnfUuzxWmWu8TSg3Yayj9OSHXUi143K1V2tQuampX25y+THp53frXzDWA/niWnNajfTTciVSLehbkR7bsji5mrYfY95MhpOaA0pP+tg92n+atfUAbmowM6sxNzWYmdWYA6+ZWY058JqZ1ZgDr5lZjTnwmpnVmAOvmVmN/X8ZbdZDhTH/pQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exhaustive evaluation of FR systems\n",
        "\n",
        "In this section we will evaluate all unique pairwise combinations of face detectors and face verifiers. There are a few caveats to this:\n",
        "\n",
        " - Currently, we are using the face recognition function provided in the deepface framework and it does not handle images with no faces. This might not sound like a problem, until one of the face detectors fail to detect a face in an image, raising the error. The opencv, ssd and dlib face detectors all failed at some point, so are currently not included in this exhaustive evaluation.\n",
        "\n",
        " - The 'mediapipe' face detector is currently bugged: the function does not recognize it as a valid face detector despite it being a valid one.\n",
        "\n",
        "This means that the following face detectors and verifiers are considered in the exhaustive evaluation:\n",
        "  - Face detectors:\n",
        "    - MTCNN\n",
        "    - RetinaFace\n",
        "  - Face verifiers:\n",
        "    - VGG-Face\n",
        "    - Facenet\n",
        "    - Facenet512\n",
        "    - OpenFace\n",
        "    - DeepFace\n",
        "    - DeepID\n",
        "    - ArcFace\n",
        "    - Dlib\n",
        "    - Ensemble\n",
        "\n",
        "Note: the ensemble face verifier uses the VGG-Face, Facenet, OpenFace, and DeepFace models along with all three metrics: cosine, euclidean and euclidean_l2.\n",
        "\n",
        "The performance results are printed subsequently. These results include a confusion matrix plot along with important performance metrics: accuracy, false positive, false negatives, true positives and true negatives."
      ],
      "metadata": {
        "id": "sB7bgk11wN8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT NOTE / CONSIDERATION:\n",
        "# When the backend fails to detect a face, the entire face recognition system\n",
        "# fails with an error. It will be necessary to modify this behaviour at least\n",
        "# within the face recogniton function for it to be able to continue!\n",
        "\n",
        "# Performs exhaustive evaluation on the LFW subset\n",
        "all_perf_results, gt = exhaustive_LFW_eval(LFW_SUB_ROOT)"
      ],
      "metadata": {
        "id": "tJqb4qlwxPLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the performance results of each face detector + verifier pair\n",
        "for result in all_perf_results:\n",
        "    result.plot_performance()"
      ],
      "metadata": {
        "id": "YDACn9lHya5f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}