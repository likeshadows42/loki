{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy                as np\n",
    "import sqlalchemy           as sqla\n",
    "import matplotlib.image     as mpimg\n",
    "import matplotlib.pyplot    as plt\n",
    "import api.global_variables as glb\n",
    "\n",
    "from re                     import compile, IGNORECASE\n",
    "from tqdm                   import tqdm\n",
    "from uuid                   import UUID\n",
    "from filecmp                import cmp\n",
    "from IFR.api                import *\n",
    "from IFR.classes            import *\n",
    "from IFR.functions          import *\n",
    "from sklearn.cluster        import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles / flags:\n",
    "build_n_save      = False # build and save face detectors & verifiers\n",
    "create_database   = False # create database\n",
    "save_new_database = True  # save database\n",
    "align             = True  # perform face alignment\n",
    "\n",
    "# Paths:\n",
    "saved_detectors = 'api/saved_models/detectors' # face detector save directory\n",
    "saved_verifiers = 'api/saved_models/verifiers' # face verifier save directory\n",
    "\n",
    "SQLITE_DB_FP    = 'api/data/database/loki.sqlite' # full path of new database\n",
    "img_path        = 'api/data/img'                       # image directory to be used\n",
    "\n",
    "# Other:\n",
    "load_detectors  = ['retinaface']\n",
    "load_verifiers  = ['ArcFace']\n",
    "\n",
    "use_detector    = 'retinaface'\n",
    "use_verifier    = 'ArcFace'\n",
    "\n",
    "normalization   = 'base'\n",
    "metric          = 'cosine'\n",
    "\n",
    "# DBSCAN\n",
    "dbscan_eps         = 0.5\n",
    "dbscan_min_samples = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds and saves face detectors and verifiers (depending on 'build_n_save')\n",
    "if build_n_save:\n",
    "    # All face detector and verifier names\n",
    "    detector_names = ['opencv', 'ssd', 'mtcnn', 'retinaface']\n",
    "    verifier_names = ['VGG-Face', 'Facenet', 'Facenet512', 'OpenFace',\n",
    "                      'DeepFace', 'DeepID' , 'ArcFace']\n",
    "\n",
    "    # Builds all face detectors and verifiers\n",
    "    detectors = batch_build_detectors(detector_names, show_prog_bar=True,\n",
    "                                        verbose=False)\n",
    "    verifiers = batch_build_verifiers(verifier_names, show_prog_bar=True,\n",
    "                                        verbose=False)\n",
    "\n",
    "    # Prints the number of face detectors and verifiers built\n",
    "    print('Number of detectors built:', len(detectors))\n",
    "    print('Number of verifiers built:', len(verifiers), '\\n')\n",
    "\n",
    "    # Saves each face detector model\n",
    "    for name, obj in detectors.items():\n",
    "        status = save_built_model(name, obj, saved_detectors, overwrite=True,\n",
    "                                    verbose=True)\n",
    "    print('')\n",
    "\n",
    "    # Saves each face verifier model\n",
    "    for name, obj in verifiers.items():\n",
    "        status = save_built_model(name, obj, saved_verifiers, overwrite=True,\n",
    "                                    verbose=True)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Loading / creating face detectors ---------------------\n",
    "\n",
    "# Loads (or creates) all face detectors\n",
    "print('  -> Loading / creating face detectors:')\n",
    "detector_models = init_load_detectors(load_detectors, saved_detectors)\n",
    "print('\\n> Detectors:', detector_models, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Loading / creating face verifiers ---------------------\n",
    "\n",
    "# Loads (or creates) all face verifiers\n",
    "print('  -> Loading / creating face verifiers:')\n",
    "verifier_models = init_load_verifiers(load_verifiers, saved_verifiers)\n",
    "print('\\n> Verifiers:', verifier_models, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tries to load a database if it exists. If not, create a new one.\n",
    "print('  -> Loading / creating database: ', end='')\n",
    "glb.sqla_engine = load_database(SQLITE_DB_FP)\n",
    "if glb.sqla_engine is None:\n",
    "    raise AssertionError('Failed to load or create database!')\n",
    "else:\n",
    "    print('success!')\n",
    "print('')\n",
    "\n",
    "# Tries to load a session if it exists. If not, create a new one.\n",
    "print('  -> Loading / creating session: ', end='')\n",
    "glb.sqla_session = start_session(glb.sqla_engine)\n",
    "if glb.sqla_session is None:\n",
    "    raise AssertionError('Failed to create session!')\n",
    "else:\n",
    "    print('success!')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def process_image_zip_file_nb(myfile, image_dir, t_check=True, n_token=2,\n",
    "                              valid_exts=['.jpg', '.png', '.npy']):\n",
    "    \"\"\"\n",
    "    Processes a zip file containing image files. The zip file ('myfile') is\n",
    "    assumed to have only valid image files (i.e. '.jpg', '.png', etc).\n",
    "    \n",
    "    The contents of the zip file are extracted to a named temporary directory.\n",
    "    Then each file is checked to see if they have already been processed (exists\n",
    "    with the same file name and size in the ProcessedFiles table of the\n",
    "    database) OR if they are duplicate files. A file is considered a duplicate\n",
    "    if there is at least one file in the 'image_dir' directory that:\n",
    "        \n",
    "        1. has the same file size (checked via filecmp.cmp(..., shallow=False))\n",
    "        2. has the same contents (checked via filecmp.cmp(..., shallow=False))\n",
    "        3. has the same image width and height (checked via imagesize)\n",
    "    \n",
    "    An existing file or duplicate file is ignored during the extraction process.\n",
    "    If 'auto_rename' is True, then each unique file with the same name as a file\n",
    "    in 'image_dir' directory gets renamed to a unique identifier using uuid4()\n",
    "    from the uuid library. If, however, 'auto_rename' is False then the file is\n",
    "    also skipped despite being a unique file.\n",
    "\n",
    "    Finally, all unique (possibly renamed) files are moved from the temporary\n",
    "    directory to the 'image_dir' directory, and the temporary directory is\n",
    "    deleted.\n",
    "\n",
    "    Effectively, this function attempts to extract only unique (non-existing)\n",
    "    image files from the zip file provided and rename them if necessary.\n",
    "\n",
    "    Inputs:\n",
    "        1. myfile      - zip file obtained through FastAPI [zip file].\n",
    "\n",
    "        2. image_dir   - path to directory in which the extracted images will be\n",
    "                            saved to [string].\n",
    "\n",
    "        3. auto_rename - toggles between automatic renaming of image files with\n",
    "                            a non-unique name [boolean, default=True].\n",
    "\n",
    "    Output:\n",
    "        1. list with the paths of each image file that was skipped [list of\n",
    "            strings].\n",
    "\n",
    "    Signature:\n",
    "        skipped_files = process_image_zip_file_nb(myfile, image_dir,\n",
    "                                            t_check=True, n_token=2,\n",
    "                                            valid_exts=['.jpg', '.png', '.npy'])\n",
    "    \"\"\"\n",
    "    # Create temporary directory and extract all files to it\n",
    "    with TemporaryDirectory(prefix=\"process_image_zip_file-\") as tempdir:\n",
    "        # with ZipFile(BytesIO(myfile.file.read()), 'r') as myzip:\n",
    "        with ZipFile(myfile, 'r') as myzip:\n",
    "            # Extracts all files in the zip file to a temporary directory,\n",
    "            # flattens the directory structure and filters the files by valid\n",
    "            # extensions\n",
    "            myzip.extractall(path=tempdir)\n",
    "            flatten_dir_structure(tempdir, valid_exts=valid_exts,\n",
    "                                    n_token=n_token)\n",
    "\n",
    "            # Obtains the files' paths, removes corrupted images and creates a\n",
    "            # new list with only the uncorrupted files\n",
    "            all_tpaths = [os.path.join(tempdir, file) for file\\\n",
    "                        in os.listdir(tempdir)]\n",
    "            tpaths     = []\n",
    "            for pth in all_tpaths:\n",
    "                if not image_is_uncorrupted(pth, transpose_check=t_check):\n",
    "                    os.remove(pth)     # deletes corrupted images\n",
    "                else:\n",
    "                    tpaths.append(pth) # appends valid path to tpaths\n",
    "\n",
    "            # Repopulates the 'proc_files_temp' table\n",
    "            if repopulate_temp_file_table(tpaths):\n",
    "                raise AssertionError(\"Could not repopulate\"\\\n",
    "                                   + \"'proc_files_temp' table.\")\n",
    "\n",
    "            # Queries the database to figure out which files have the SAME size\n",
    "            query  = select(ProcessedFiles.filename,\n",
    "                            ProcessedFilesTemp.filename).join(\\\n",
    "                            ProcessedFilesTemp, ProcessedFiles.filesize ==\\\n",
    "                            ProcessedFilesTemp.filesize)\n",
    "            result = glb.sqla_session.execute(query)\n",
    "\n",
    "            # Initializes the skipped_files list then loops through each matched\n",
    "            # & temporary file pairs in the query's result\n",
    "            skipped_files = []\n",
    "            for fname, tname in result:\n",
    "                # Obtains the full path of the matched & temporary files\n",
    "                fname_fullpath = os.path.join(image_dir, fname)\n",
    "                tname_fullpath = os.path.join(tempdir, tname)\n",
    "                \n",
    "                # Checks if the files are different or not\n",
    "                if not cmp(fname_fullpath, tname_fullpath):\n",
    "                    # Files are different, so check if they have the same name\n",
    "                    if fname == tname:\n",
    "                        # Names are the same, so rename them\n",
    "                        tname = rename_file_w_hex_token(tname)\n",
    "                    \n",
    "                    # Determines the new full path for tname and moves the file\n",
    "                    tname_fullpath_dest = os.path.join(image_dir, tname)\n",
    "                    sh_move(tname_fullpath, tname_fullpath_dest)\n",
    "\n",
    "                else:\n",
    "                    # Files are the same, so remove it from tempdir\n",
    "                    os.remove(tname_fullpath)\n",
    "                    skipped_files.append(tname)\n",
    "\n",
    "            # Queries for files that have SAME name and DIFFERENT size from the\n",
    "            # existing ones that have to be renamed\n",
    "            query = select(ProcessedFilesTemp.filename).join(ProcessedFiles,\n",
    "                    (ProcessedFilesTemp.filename == ProcessedFiles.filename)\\\n",
    "                    & (ProcessedFilesTemp.filesize != ProcessedFiles.filesize))\n",
    "            result = glb.sqla_session.execute(query)\n",
    "\n",
    "            # Loops through each row in result\n",
    "            for row in result:\n",
    "                # Obtains the file name and renames it\n",
    "                filename         = row.filename\n",
    "                filename_renamed = rename_file_w_hex_token(filename)\n",
    "                print(filename_renamed, filename)\n",
    "\n",
    "                # Moves the file to the appropriate location\n",
    "                sh_move(os.path.join(tempdir, filename),\n",
    "                        os.path.join(tempdir, filename_renamed))\n",
    "\n",
    "            # Now it's safe to move the remaining files in tempdir directly to\n",
    "            # img_dir\n",
    "            for file in os.listdir(tempdir):\n",
    "                # Moves each file to the appropriate location (ensuring it is\n",
    "                # not a directory)\n",
    "                if not os.path.isdir(os.path.join(tempdir, file)):\n",
    "                    sh_move(os.path.join(tempdir,file),\n",
    "                            os.path.join(image_dir, file))\n",
    "\n",
    "    return skipped_files\n",
    "    \n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def process_faces_from_dir(img_dir, detector_models, verifier_models,\n",
    "                        detector_name='retinaface', verifier_names=['ArcFace'],\n",
    "                        normalization='base', align=True, auto_grouping=True, \n",
    "                        eps=0.5, min_samples=2, metric='cosine', pct=0.02,\n",
    "                        check_models=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Processes face images contained in the directory 'img_dir'. If there are no\n",
    "    images in the directory, an assertion error is raised. The 'processing'\n",
    "    includes the following steps, performed per image:\n",
    "        1. Faces are detected in the image using the 'detector_name' face\n",
    "            detector.\n",
    "\n",
    "        2. If a detected face (region) is too small, it is discarded. This\n",
    "            filtering is determined by 'pct'. If a region's area is smaller than\n",
    "            the original image's area multiplied by this percentage factor\n",
    "            'pct', then it is discarded. This helps with detection of tiny faces\n",
    "            which are not useful for recognition.\n",
    "\n",
    "        3. For each filtered face, the deep neural embeddings (which is just a\n",
    "            vector representation of the face) is calculated.\n",
    "\n",
    "        4. A face representation object (see help(FaceRep) for more details) is\n",
    "            created for each face and added (but not committed!) to the current\n",
    "            session.\n",
    "\n",
    "    An optional 'fifth' step is performed if 'auto_grouping' is True. The\n",
    "    function tries to group similar face representations using the DBSCAN\n",
    "    algorithm on the embeddings, such that each group corresponds to faces of\n",
    "    (ideally) the same person. If multiple face verifiers were passed to this\n",
    "    function, the grouping is performed using the embeddings obtained from the\n",
    "    FIRST face verifier in the list.\n",
    "\n",
    "    If 'check_models' is True, then the function ensures that:\n",
    "        1. the 'detector_name' face detector is in the 'detector_models'\n",
    "            dictionary.\n",
    "\n",
    "        2. the 'verifier_names' face verifier is in the 'verifier_models'\n",
    "            dictionary.\n",
    "\n",
    "    In both cases, if a detector or verifier is not in the respective\n",
    "    dictionary, the function attempts to build them from scratch. If the\n",
    "    building process fails, then an assertion error is raised as either a face\n",
    "    detector and/or verifier will be missing.\n",
    "\n",
    "    IMPORTANT: This function uses the 'sqla_session' global variable from the\n",
    "    'global_variables.py' module to add changes (but not commit) to the SQL\n",
    "    alchemy session.\n",
    "\n",
    "    Inputs:\n",
    "         1. img_dir         - full path to the directory containing the images\n",
    "                                [string].\n",
    "\n",
    "         2. detector_models - dictionary of face detector model names (keys) and\n",
    "                                objects (values) [dictionary].\n",
    "\n",
    "         3. verifier_models - dictionary of face verifier model names (keys) and\n",
    "                                objects (values) [dictionary].\n",
    "\n",
    "         4. detector_name   - chosen face detector's name. Options: opencv, ssd,\n",
    "                                mtcnn or retinaface [string,\n",
    "                                default='retinaface'].\n",
    "\n",
    "         5. verifier_names  - chosen face verifiers' name(s). Options: VGG-Face,\n",
    "                                OpenFace, Facenet, Facenet512, DeepFace, DeepID\n",
    "                                and ArcFace. Can be either a string (with a\n",
    "                                single name) or a list of string (with several\n",
    "                                names) [string or list of strings,\n",
    "                                default=['ArcFace']].\n",
    "\n",
    "         6. normalization   - normalizes the face image and may increase face\n",
    "                                recognition performance depending on the\n",
    "                                normalization type and the face verifier model.\n",
    "                                Options: base, raw, Facenet, Facenet2018,\n",
    "                                VGGFace, VGGFace2 and ArcFace [string,\n",
    "                                default='base'].\n",
    "        \n",
    "         7. align           - toggles if face images should be aligned. This\n",
    "                                improves face recognition performance at the\n",
    "                                cost of some speed [boolean, default=True].\n",
    "\n",
    "         8. auto_grouping   - toggles whether the faces should be grouped\n",
    "                                automatically using the DBSCAN algorithm. If\n",
    "                                multiple verifier names are passed, uses the\n",
    "                                embeddings of the first verifier during the\n",
    "                                clustering procedure [boolean, default=True].\n",
    "\n",
    "         9. eps             - the maximum distance between two samples for one\n",
    "                                to be considered as in the neighborhood of the\n",
    "                                other. This is the most important DBSCAN\n",
    "                                parameter to choose appropriately for the\n",
    "                                specific data set and distance function\n",
    "                                [float, default=0.5].\n",
    "\n",
    "        10. min_samples     - the number of samples (or total weight) in a\n",
    "                                neighborhood for a point to be considered as a\n",
    "                                core point. This includes the point itself\n",
    "                                [integer, min_samples=2].\n",
    "\n",
    "        11. metric          - the metric used when calculating distance between\n",
    "                                instances in a feature array. It must be one of\n",
    "                                the options allowed by\n",
    "                                sklearn.metrics.pairwise_distances\n",
    "                                [string, default='cosine'].\n",
    "\n",
    "        12. pct             - percentage of image area as a decimal. This will\n",
    "                                be used to filter out 'small' detections [float,\n",
    "                                default=0.02].\n",
    "\n",
    "        12. check_models    - toggles if the function should ensure the face \n",
    "                                detectors and verifiers are contained in the\n",
    "                                respective dictionaries [boolean, default=True].\n",
    "            \n",
    "        14. verbose         - toggles the function's warnings and other messages\n",
    "                                [boolean, default=True].\n",
    "\n",
    "    Output:\n",
    "        1. returns a list of the FaceRep objects created [list of FaceRep\n",
    "            objects].\n",
    "\n",
    "    Signature:\n",
    "        records = process_faces_from_dir(img_dir, detector_models,\n",
    "                        verifier_models, detector_name='retinaface',\n",
    "                        verifier_names=['ArcFace'], normalization='base',\n",
    "                        align=True, auto_grouping=True, eps=0.5, min_samples=2,\n",
    "                        metric='cosine', check_models=True, verbose=False)\n",
    "    \"\"\"\n",
    "    # Initializes records (which will be a list of FaceReps)\n",
    "    records = []\n",
    "\n",
    "    # Assuming img_dir is a directory containing images\n",
    "    img_paths = get_image_paths(img_dir)\n",
    "    img_paths.sort()\n",
    "\n",
    "    # No images found, do something about it\n",
    "    if len(img_paths) == 0:\n",
    "        # Does something about the fact that there are no images in the\n",
    "        # directory - for now just raise an assertion error\n",
    "        raise AssertionError('No images in the directory specified')\n",
    "\n",
    "    # Ensures that the face detector and verifiers exist\n",
    "    if check_models:\n",
    "        # Ensures face detectors exist\n",
    "        ret1, detector_models = ensure_detectors_exists(models=detector_models,\n",
    "                                                detector_names=[detector_name],\n",
    "                                                verbose=verbose)\n",
    "\n",
    "        # Ensures face verifiers exist\n",
    "        ret2, verifier_models = ensure_verifiers_exists(models=verifier_models,\n",
    "                                                verifier_names=verifier_names,\n",
    "                                                verbose=verbose)\n",
    "\n",
    "        # Asserts that the face detectors and verifiers exist\n",
    "        assert ret1 and ret2, f'Could not ensure existence of '\\\n",
    "                            + f'face detectors ({ret1}) or verifiers ({ret2})!'\n",
    "\n",
    "    # If auto grouping is True, then initialize the embeddings list\n",
    "    if auto_grouping:\n",
    "        embds = []\n",
    "    \n",
    "    # Obtains the processed files names from the ProcessedFiles table to skip\n",
    "    # already processed files\n",
    "    proc_fnames = glb.sqla_session.query(ProcessedFiles.filename)\n",
    "    proc_fnames = [item[0] for item in proc_fnames.all()]\n",
    "\n",
    "    # Creates the progress bar\n",
    "    n_imgs = len(img_paths)\n",
    "    pbar   = tqdm(range(0, n_imgs), desc='Processing face images',\n",
    "                    disable=False)\n",
    "\n",
    "    # Loops through each image in the 'img_dir' directory\n",
    "    for index, i, img_path in zip(pbar, range(0, n_imgs), img_paths):\n",
    "        # Skips the current file if it has already been processed\n",
    "        if img_path[img_path.rindex('/')+1:] in proc_fnames:\n",
    "            if glb.DEBUG:\n",
    "                print(f'Skipping: {img_path}'.ljust(40), '(already processed)')\n",
    "            continue\n",
    "\n",
    "        # Detects faces\n",
    "        output = do_face_detection(img_path, detector_models=detector_models,\n",
    "                                    detector_name=detector_name, align=align,\n",
    "                                    verbose=verbose)\n",
    "\n",
    "        # Filter regions & faces which are too small\n",
    "        image_size             = mpimg.imread(img_path).shape\n",
    "        filtered_regions, idxs = discard_small_regions(output['regions'],\n",
    "                                                        image_size, pct=pct)\n",
    "        filtered_faces         = [output['faces'][i] for i in idxs]\n",
    "\n",
    "        # Calculates the deep neural embeddings for each face image in outputs\n",
    "        embeddings = calc_embeddings(filtered_faces, verifier_models,\n",
    "                                     verifier_names=verifier_names,\n",
    "                                     normalization=normalization)\n",
    "\n",
    "        # Loops through each (region, embedding) pair and create a record\n",
    "        # (FaceRep object)\n",
    "        for region, cur_embds in zip(filtered_regions, embeddings):\n",
    "            # id        - handled by sqlalchemy\n",
    "            # person_id - dont now exactly how to handle this (sqlalchemy?)\n",
    "            # image_name_orig = img_path.split('/')[-1]\n",
    "            # image_fp_orig   = img_path\n",
    "            # image_name      = ''   # currently not being used in this approach\n",
    "            # image_fp        = ''   # currently not being used in this approach\n",
    "            # group_no        = -1\n",
    "            # region          = region\n",
    "            # embeddings      = cur_embds\n",
    "            record = FaceRep(image_name_orig=img_path.split('/')[-1],\n",
    "                        image_name='', image_fp_orig=img_path,\n",
    "                        image_fp='', group_no=-1, region=region,\n",
    "                        embeddings=cur_embds)\n",
    "            \n",
    "            # Appends each record to the records list\n",
    "            records.append(record)\n",
    "\n",
    "            # If auto grouping is True, then store each calculated embedding\n",
    "            if auto_grouping:\n",
    "                embds.append(cur_embds[verifier_names[0]])\n",
    "\n",
    "        # After file has been processed, add it to the ProcessedFiles table\n",
    "        glb.sqla_session.add(ProcessedFiles(filename=img_path.split('/')[-1],\n",
    "                                            # filepath=img_path,\n",
    "                                            filesize=os.path.getsize(img_path)))\n",
    "    \n",
    "    if glb.DEBUG:\n",
    "        print('Commits processed files')\n",
    "    glb.sqla_session.commit()\n",
    "\n",
    "    # Clusters Representations together using the DBSCAN algorithm\n",
    "    if auto_grouping and len(embds) > 0:\n",
    "        # Clusters embeddings using DBSCAN algorithm\n",
    "        results = DBSCAN(eps=eps, min_samples=min_samples,\n",
    "                         metric=metric).fit(embds)\n",
    "\n",
    "        # Loops through each label and updates the 'group_no' attribute of each\n",
    "        # record IF group_no != -1 (because -1 is already the default value and\n",
    "        # means \"no group\")\n",
    "        for i, lbl in enumerate(results.labels_):\n",
    "            if lbl == -1:\n",
    "                continue\n",
    "            else:\n",
    "                records[i].group_no = int(lbl)\n",
    "\n",
    "    # Loops through each record and add them to the global session\n",
    "    if glb.DEBUG:\n",
    "        print('add representation to FaceRep table')\n",
    "    for record in records:\n",
    "        glb.sqla_session.add(record)\n",
    "    glb.sqla_session.commit()\n",
    "\n",
    "    # Add how many person to Person table as the detected clusters\n",
    "    if glb.DEBUG:\n",
    "        print('add person to Person table')\n",
    "    subquery = select(FaceRep.group_no).where(FaceRep.group_no > -1).group_by(FaceRep.group_no).order_by(FaceRep.group_no)\n",
    "    query = insert(Person).from_select([\"group_no\"], subquery)\n",
    "    glb.sqla_session.execute(query)\n",
    "    glb.sqla_session.commit()\n",
    "\n",
    "    # Populate the person_id field in FaceRep with the corresponding ID in Person table\n",
    "    if glb.DEBUG:\n",
    "        print('Create joins between Person and FaceRep tables')\n",
    "    subquery = select(Person.id).where(FaceRep.group_no == Person.group_no).where(FaceRep.group_no > -1)\n",
    "    query = update(FaceRep).values(person_id = subquery.scalar_subquery()).where(FaceRep.group_no > -1)\n",
    "    if glb.DEBUG:\n",
    "        print(query)\n",
    "    glb.sqla_session.execute(query)\n",
    "    glb.sqla_session.commit()\n",
    "    \n",
    "    # Set group_no to -2 for the representation that have been linked with person\n",
    "    if glb.DEBUG:\n",
    "        print('Set group_no to -2 for FaceRep and Person that have been already linked together')\n",
    "    query = update(FaceRep).values(group_no = -2).where(FaceRep.group_no > -1)\n",
    "    glb.sqla_session.execute(query)\n",
    "    query = update(Person).values(group_no = -2).where(Person.group_no > -1)\n",
    "    glb.sqla_session.execute(query)\n",
    "    glb.sqla_session.commit()\n",
    "\n",
    "    # Return representation database\n",
    "    return records\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def faces_import_from_zip_nb(myfile, params, image_dir, n_token=2):\n",
    "    \"\"\"\n",
    "    API endpoint: create_database_from_zip()\n",
    "\n",
    "    Creates an SQLite database from a zip file. The zip file is expected to\n",
    "    contain image files in any of the following formats: .jpg, .png, .npy.\n",
    "\n",
    "    The images in the zip file are extracted to a temporary directory. Any image\n",
    "    with the same name of another image in the 'image directory' is either\n",
    "    renamed (auto_rename=True) or skipped (auto_rename=False). Renamed images\n",
    "    are renamed using a random unique object identifier obtained by uuid4() from\n",
    "    the uuid library.\n",
    "\n",
    "    Parameters:\n",
    "    - myfile: a zip file\n",
    "\n",
    "    - params: a structure with the following parameters:\n",
    "        1. detector_name  - name of face detector model [string].\n",
    "        2. verifier_names - list of names of face verifier models [list of\n",
    "                            strings].\n",
    "        3. align          - perform face alignment flag (default=True)\n",
    "                            [boolean].\n",
    "        4. normalization  - name of image normalization [string].\n",
    "        5. auto_grouping  - toggles whether Representations should be grouped /\n",
    "                            clusted automatically using the DBSCAN algorithm\n",
    "                            (default=True) [boolean].\n",
    "        6. eps            - maximum distance between two samples for one to be\n",
    "                            considered as in the neighborhood of the other. This\n",
    "                            is the most important DBSCAN parameter to choose\n",
    "                            appropriately for the specific data set and distance\n",
    "                            function (default=0.5) [float].\n",
    "        7. min_samples    - the number of samples (or total weight) in a\n",
    "                            neighborhood for a point to be considered as a core\n",
    "                            point. This includes the point itself\n",
    "                            (min_samples=2) [integer].\n",
    "        8. metric         - the metric used when calculating distance between\n",
    "                            instances in a feature array. It must be an option\n",
    "                            allowed by sklearn.metrics.pairwise_distances\n",
    "                            (default='cosine') [string].\n",
    "        9. pct            - used to filter faces which are smaller than this\n",
    "                            percentage of the original image's area (width x\n",
    "                            height) [float].\n",
    "       10. check_models   - toggles if the function should check if all desired\n",
    "                            face detector & verifiers are correctly loaded. If\n",
    "                            they are not, builds them from scratch, exitting if\n",
    "                            the building fails [boolean].\n",
    "       11. verbose        - output messages to server's console [boolean].\n",
    "\n",
    "        [Example] JSON schema:\n",
    "        {\n",
    "          \"detector_name\": \"retinaface\",\n",
    "          \"verifier_names\": [\"ArcFace\"],\n",
    "          \"align\": true,\n",
    "          \"normalization\": \"base\",\n",
    "          \"auto_grouping\": true,\n",
    "          \"eps\": 0.5,\n",
    "          \"min_samples\": 2,\n",
    "          \"metric\": \"cosine\",\n",
    "          \"pct\": 0.02,\n",
    "          \"check_models\": true,\n",
    "          \"verbose\": false\n",
    "        }\n",
    "\n",
    "    - image_dir   : full path to directory containing images (string,\n",
    "                     default: <glb.IMG_DIR>)\n",
    "\n",
    "    - db_dir      : full path to directory containing saved database (string,\n",
    "                     default: <glb.RDB_DIR>)\n",
    "\n",
    "    - auto_rename : flag to force auto renaming of images in the zip file with\n",
    "                     names that match images already in the image directory\n",
    "                     (boolean, default: True)\n",
    "\n",
    "    - force_create: flag to force database creation even if one already exists,\n",
    "                     overwritting the old one (boolean, default: True)\n",
    "\n",
    "    Output:\\n\n",
    "        JSON-encoded dictionary with the following key/value pairs is returned:\n",
    "            1. length: length of the newly created database OR of the currently\n",
    "                loaded one if this process is skipped (i.e. force_create=False\n",
    "                with existing database loaded)\n",
    "            \n",
    "            2. message: informative message string\n",
    "    \"\"\"   \n",
    "    # These are hard-codded constants for now\n",
    "    table_names = ['person', 'representation', 'proc_files', 'proc_files_temp']\n",
    "    valid_exts  = ['.jpg', '.png', '.npy']\n",
    "\n",
    "    # Initialize output message and skipped_files list\n",
    "    output_msg    = ''\n",
    "    skipped_files = []\n",
    "\n",
    "    # If image directory provided is None or is not a directory, use default\n",
    "    # directory\n",
    "    if not image_dir or not os.path.isdir(image_dir):\n",
    "        global img_dir\n",
    "        output_msg += 'Image dir is None, does not exist or is not a '\\\n",
    "                   +  'directory. Using default directory instead.\\n'\n",
    "        image_dir = img_dir\n",
    "\n",
    "    # Database does not exist\n",
    "    if  database_is_empty(glb.sqla_engine):\n",
    "        # Do nothing, but set message\n",
    "        output_msg += 'Database does not exist! '\\\n",
    "                   +  'Please create one before using this endpoint.\\n'\n",
    "\n",
    "    # Face Representation table does not exist\n",
    "    elif not all_tables_exist(glb.sqla_engine, table_names):\n",
    "        # Do nothing, but set message\n",
    "        output_msg += \"Face representation table ('representation') \"\\\n",
    "                   +  'does not exist! Please ensure that this table exists '\\\n",
    "                   +  'before using this endpoint.\\n'\n",
    "\n",
    "    # Otherwise (database is not empty and table exists), \n",
    "    else:\n",
    "        # Initialize dont_skip flag as True\n",
    "        dont_skip   = True\n",
    "\n",
    "        # Extract zip files\n",
    "        output_msg += 'Extracting images in zip:'\n",
    "        skipped_files = []\n",
    "\n",
    "        try:\n",
    "            # Process the zip file containing the image files\n",
    "            skipped_files = process_image_zip_file_nb(myfile, image_dir,\n",
    "                                            t_check=t_check, n_token=n_token,\n",
    "                                            valid_exts=valid_exts)\n",
    "            output_msg += ' success! '\n",
    "\n",
    "        except Exception as excpt:\n",
    "            dont_skip   = False\n",
    "            output_msg += f' failed (reason: {excpt}).'\n",
    "\n",
    "        # Processes face images from the image directory provided if 'dont_skip'\n",
    "        # is True\n",
    "        if dont_skip:\n",
    "            output_msg += 'Creating database: '\n",
    "\n",
    "            records = process_faces_from_dir(image_dir,\n",
    "                            detector_models, verifier_models,\n",
    "                            detector_name  = params.detector_name,\n",
    "                            verifier_names = params.verifier_names,\n",
    "                            normalization  = params.normalization,\n",
    "                            align          = params.align,\n",
    "                            auto_grouping  = params.auto_grouping,\n",
    "                            eps            = params.eps,\n",
    "                            min_samples    = params.min_samples,\n",
    "                            metric         = params.metric,\n",
    "                            pct            = params.pct,\n",
    "                            check_models   = params.check_models,\n",
    "                            verbose        = params.verbose)\n",
    "        \n",
    "            # Commits the records and updates the message\n",
    "            glb.sqla_session.commit()\n",
    "            output_msg += ' success!'\n",
    "        else:\n",
    "            records = []\n",
    "\n",
    "    return {'n_records':len(records), 'n_skipped':len(skipped_files),\n",
    "            'skipped_files':skipped_files, 'message':output_msg}\n",
    "\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_dir       = 'api/data/img'\n",
    "detector_name  = 'retinaface'\n",
    "verifier_names = ['ArcFace']\n",
    "align          = True\n",
    "show_prog_bar  = False\n",
    "tags           = []\n",
    "uids           = []\n",
    "normalization  = 'base'\n",
    "auto_grouping  = True\n",
    "eps            = 0.5\n",
    "min_samples    = 2\n",
    "metric         = 'cosine'\n",
    "pct            = 0.02\n",
    "check_models   = False\n",
    "verbose        = False\n",
    "image_dir      = glb.IMG_DIR\n",
    "auto_rename    = True\n",
    "t_check        = True\n",
    "n_token        = 2\n",
    "valid_exts     = ['.jpg', '.png', '.npy']\n",
    "\n",
    "glb.DEBUG      = False\n",
    "\n",
    "# Params structure\n",
    "params = CreateDatabaseParams(detector_name  = detector_name,\n",
    "                              verifier_names = verifier_names,\n",
    "                              align          = align,\n",
    "                              normalization  = normalization,\n",
    "                              auto_grouping  = auto_grouping,\n",
    "                              eps            = eps,\n",
    "                              min_samples    = min_samples,\n",
    "                              metric         = metric,\n",
    "                              pct            = pct,\n",
    "                              check_models   = check_models,\n",
    "                              verbose        = verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populating database from dir or zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process faces from directory\n",
    "do_process_faces_from_dir = False\n",
    "if do_process_faces_from_dir:\n",
    "    records = process_faces_from_dir(test_dir,\n",
    "                                        detector_models, verifier_models,\n",
    "                                        detector_name  = detector_name,\n",
    "                                        verifier_names = verifier_names,\n",
    "                                        normalization  = normalization,\n",
    "                                        align          = align,\n",
    "                                        auto_grouping  = auto_grouping,\n",
    "                                        eps            = eps,\n",
    "                                        min_samples    = min_samples,\n",
    "                                        metric         = metric,\n",
    "                                        pct            = pct,\n",
    "                                        check_models   = check_models,\n",
    "                                        verbose        = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate faces from zip\n",
    "test_faces_import_from_zip_nb = False\n",
    "if test_faces_import_from_zip_nb:\n",
    "    myfile = 'api/data/test2b.zip'\n",
    "\n",
    "    output = faces_import_from_zip_nb(myfile, params, image_dir)\n",
    "    print('\\n', output, '\\n', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image zip file\n",
    "do_process_image_zip_file_nb = False\n",
    "if do_process_image_zip_file_nb:\n",
    "    myfiles = ['api/data/test1a.zip',\n",
    "               'api/data/test2.zip']\n",
    "\n",
    "    for myfile in myfiles:\n",
    "        print(f'Current zip {myfile}:')\n",
    "        skipped_files = process_image_zip_file_nb(myfile, image_dir,\n",
    "                                            t_check=True, n_token=2,\n",
    "                                            valid_exts=['.jpg', '.png', '.npy'])\n",
    "        print(f'Skipped files (# {len(skipped_files)}):')\n",
    "        for i, f in enumerate(skipped_files):\n",
    "            print(f'  > ({i}) {f}')\n",
    "        if len(skipped_files) == 0:\n",
    "            print('  None\\n')\n",
    "        else:\n",
    "            print('')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group2person_map(group_nos, person_ids):\n",
    "    unique_gnos   = np.unique(group_nos)\n",
    "    new_person_id = max(person_ids) + 1\n",
    "\n",
    "    group2person = {}\n",
    "    for u_gno in unique_gnos:\n",
    "        # Determines the person id associated to the group number\n",
    "        est_person_id = np.bincount(person_ids[group_nos == u_gno]).argmax()\n",
    "\n",
    "        if est_person_id == 0:\n",
    "            est_person_id  = new_person_id\n",
    "            new_person_id += 1\n",
    "\n",
    "        print('unique group no:', u_gno, ' |  est. person id:', est_person_id)\n",
    "\n",
    "        group2person[u_gno] = est_person_id\n",
    "\n",
    "    return group2person\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def group_embeddings(verifier_name, eps=0.5, min_samples=2, metric='cosine'):\n",
    "    # Attempts to get all embeddings stored in the database, given the chosen\n",
    "    # verifier model's name\n",
    "    try:\n",
    "        embds = get_embeddings_as_array(verifier_name)\n",
    "    except Exception as excpt:\n",
    "        print(f'Could not get embeddings (reason: {excpt})')\n",
    "        raise AssertionError('Could not get embeddings.')\n",
    "\n",
    "    # Clusters embeddings using DBSCAN algorithm\n",
    "    result = DBSCAN(eps=eps, min_samples=min_samples, metric=metric).fit(embds)\n",
    "\n",
    "    # Gets all person ids\n",
    "    stmt       = select(FaceRep.person_id)\n",
    "    qry_result = glb.sqla_session.execute(stmt)\n",
    "    #person_ids = [id[0] for id in qry_result.all()]\n",
    "\n",
    "    person_ids = []\n",
    "    for id in qry_result.all():\n",
    "        if id[0] is not None:\n",
    "            person_ids.append(id[0])\n",
    "        else:\n",
    "            person_ids.append(0)\n",
    "\n",
    "    person_ids   = np.array(person_ids)\n",
    "    group_nos    = np.array(result.labels_)\n",
    "\n",
    "    group2person = create_group2person_map(group_nos, person_ids)\n",
    "\n",
    "    stmt = update(FaceRep).values(group_no=group_nos)\n",
    "    glb.sqla_session.execute(stmt)\n",
    "    glb.sqla_session.commit()\n",
    "\n",
    "\n",
    "\n",
    "    return person_ids, group_nos, group2person, result\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# for updating the FaceRep inside a cluster, then use this query:\n",
    "# (existing_person_id is the value you got from previous query)\n",
    "\n",
    "# update(FaceRep).values(person_id = existing_person_id).where((FaceRep.group_no == cluster_x) & (FaceRep.person_id == None))\n",
    "\n",
    "\n",
    "# Analytically, these are the steps after inporting new images:\n",
    "\n",
    "# 1. run DBSCAN on all the images in img_dir. This will fill group_no field with cluster ID for both existing and new images.\n",
    "# 2. for each cluster:\n",
    "#   2.1. we get one record that has already person_id not null.\n",
    "#   2.2. for the remains records in the cluster that has person_id null, we will update the field with the specific ID.\n",
    "#   2.3. we set group_no = -2 for all of them in the cluster.\n",
    "\n",
    "person_ids, group_nos, group2person, dbscan_out = group_embeddings('ArcFace', eps=0.5, min_samples=2, metric='cosine')\n",
    "\n",
    "print('')\n",
    "print('g. nos'.center(6), '|', 'p. ids'.center(6))\n",
    "print('-' * 7, '|', '-' * 7, sep='')\n",
    "for pid, gnb in zip(person_ids, group_nos):\n",
    "    print(f'{gnb}'.center(6), '|', f'{pid}'.center(6))\n",
    "\n",
    "print('\\n    ', group2person, sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luca's code start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier_name = 'ArcFace'\n",
    "eps = 0.5\n",
    "min_samples = 2\n",
    "metric = 'cosine'\n",
    "\n",
    "try:\n",
    "    embds = get_embeddings_as_array(verifier_name)\n",
    "except Exception as excpt:\n",
    "    print(f'Could not get embeddings (reason: {excpt})')\n",
    "    raise AssertionError('Could not get embeddings.')\n",
    "\n",
    "# Clusters embeddings using DBSCAN algorithm\n",
    "result = DBSCAN(eps=eps, min_samples=min_samples, metric=metric).fit(embds)\n",
    "print(result.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT temp_clustering.group_no \n",
      "FROM temp_clustering\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# delete temp table\n",
    "glb.sqla_session.execute(delete(tempClustering))\n",
    "glb.sqla_session.commit()\n",
    "\n",
    "# and populate again!\n",
    "group_no = [{'group_no': int(no)} for no in result.labels_]\n",
    "query = insert(tempClustering).values(group_no)\n",
    "glb.sqla_session.execute(query)\n",
    "glb.sqla_session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the temp table\n",
    "query = select(tempClustering.group_no)\n",
    "print(query)\n",
    "result = glb.sqla_session.execute(query)\n",
    "for item in result.all():\n",
    "    print(item.group_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of ID of the new clusters\n",
    "\n",
    "new_cluster_list = []\n",
    "query = select(tempClustering.group_no).group_by(tempClustering.group_no)\n",
    "print(query)\n",
    "result = glb.sqla_session.execute(query)\n",
    "for item in result.all():\n",
    "    new_cluster_list.append(item.group_no)\n",
    "\n",
    "print(new_cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the person id for each cluster\n",
    "for cluster in new_cluster_list:\n",
    "    query = select(FaceRep.person_id).where((FaceRep.group_no == cluster) & (FaceRep.person_id != None)).limit(1)\n",
    "    result = glb.sqla_session.execute(query).first()\n",
    "    if(result):\n",
    "        #we have a match\n",
    "        print(\"match for\", cluster)\n",
    "        person_id = result.person_id\n",
    "        print(person_id)\n",
    "\n",
    "        query = update(FaceRep).values(person_id = person_id).where((FaceRep.group_no == cluster) & (FaceRep.person_id == None))\n",
    "        glb.sqla_session.execute(query)\n",
    "        glb.sqla_session.commit()\n",
    "\n",
    "    else:\n",
    "        print(\"no match for\", cluster)\n",
    "        query = text(\"SELECT rep1.id FROM representation AS rep1 WHERE (rep1.group_no == 0) & ((SELECT rep2.id FROM representation AS rep2 WHERE (rep2.group_no == 0) & (rep2.person_id IS NOT NULL)) IS NULL)\")\n",
    "        result = glb.sqla_session.execute(query)\n",
    "        for item in result:\n",
    "            print(item.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT rep1.id FROM representation AS rep1 WHERE (rep1.group_no == 0) & ((SELECT rep2.id FROM representation AS rep2 WHERE (rep2.group_no == 0) & (rep2.person_id IS NOT NULL)) IS NULL)\n",
      "1\n",
      "2\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "cluster = 0\n",
    "query = text(\"SELECT rep1.id FROM representation AS rep1 WHERE (rep1.group_no == 0) & ((SELECT rep2.id FROM representation AS rep2 WHERE (rep2.group_no == 0) & (rep2.person_id IS NOT NULL)) IS NULL)\")\n",
    "print(query)\n",
    "result = glb.sqla_session.execute(query)\n",
    "for item in result:\n",
    "    print(item.id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b8b4124e34c7aef84f71e2d1adc63dc40a11e5c939516b2a86977f9bc5888db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('loki_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a04189f248b4a4e27245eb7d1af296c0fc018dc069b6f0db3c5cdbecc6fc73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
