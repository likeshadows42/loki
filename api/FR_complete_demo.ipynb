{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a8bbcf",
   "metadata": {},
   "source": [
    "#### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import cv2\n",
    "import faiss\n",
    "import shelve\n",
    "import pickle\n",
    "\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import matplotlib.image      as mpimg\n",
    "\n",
    "\n",
    "from keras.preprocessing     import image\n",
    "from deepface.detectors      import FaceDetector\n",
    "from deepface.DeepFace       import build_model as build_verifier\n",
    "from deepface.commons        import functions, distance as dst\n",
    "from api_classes             import Representation\n",
    "from uuid                    import uuid4\n",
    "from tqdm                    import tqdm\n",
    "from timeit                  import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Path names:\n",
      "Directory api root       : /home/rpessoa/projects/loki/api\n",
      "Directory dataset root   : /home/rpessoa/projects/loki/api/data\n",
      "Directory raw            : /home/rpessoa/projects/loki/api/data/raw\n",
      "Directory targets        : /home/rpessoa/projects/loki/api/data/targets\n",
      "Directory rep. database  : /home/rpessoa/projects/loki/api/data/database\n",
      "Directory s. models      : /home/rpessoa/projects/loki/api/saved_models\n",
      "Directory s. verifiers   : /home/rpessoa/projects/loki/api/saved_models/verifiers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up paths\n",
    "API_DIR      = os.path.join(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "DST_ROOT_DIR = os.path.join(API_DIR     , 'data')\n",
    "RAW_DIR      = os.path.join(DST_ROOT_DIR, 'raw')\n",
    "#GALLERY_DIR  = os.path.join(DST_ROOT_DIR, 'gallery')\n",
    "TARGETS_DIR  = os.path.join(DST_ROOT_DIR, 'targets')\n",
    "RDB_DIR      = os.path.join(DST_ROOT_DIR, 'database')\n",
    "SVD_MDL_DIR  = os.path.join(API_DIR     , 'saved_models')\n",
    "SVD_VRF_DIR  = os.path.join(SVD_MDL_DIR , 'verifiers')\n",
    "\n",
    "directory_list       = [API_DIR, DST_ROOT_DIR, RAW_DIR, TARGETS_DIR, RDB_DIR,\n",
    "                        SVD_MDL_DIR, SVD_VRF_DIR]\n",
    "directory_list_names = ['api root', 'dataset root', 'raw', 'targets',\n",
    "                        'rep. database', 's. models', 's. verifiers']\n",
    "\n",
    "# Print path names\n",
    "print('  -> Path names:')\n",
    "for name, fp in zip(directory_list_names, directory_list):\n",
    "    print(f'Directory {name}'.ljust(25), f': {fp}', sep='')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: These functions were copied directly to the notebook to avoid conflicts\n",
    "# and issues when importing from separate Python files. FastAPI seems to work\n",
    "# with relative imports while IPYNP seems to work with absolute imports, so to\n",
    "# avoid this issue alltogether, just keep the functions local to this demo.\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "#                                   FUNCTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def get_image_paths(root_path, file_types=('.jpg', '.png'), do_sort=True):\n",
    "    \"\"\"\n",
    "    Gets the full paths of all 'file_types' files in the 'root_path' directory\n",
    "    and its subdirectories. If the 'root_path' provided points to a file, this\n",
    "    functions simply returns that path as a list with 1 element. The image path\n",
    "    list is sorted if 'do_sort' flag is set to true (default).\n",
    "\n",
    "    Inputs:\n",
    "        1. root_path  - full path of a directory\n",
    "        2. file_types - tuple containing strings of file extensions\n",
    "            ([file_types=('.jpg', '.png')])\n",
    "        3. do_sort    - boolean indicating if image path list should be sorted\n",
    "            ([do_sort=True])\n",
    "\n",
    "    Output:\n",
    "        1. list containing full path of all files in the directory and its\n",
    "            subdirectories\n",
    "\n",
    "    Example call:\n",
    "        ROOT_PATH = path/to/some/folder/dude\n",
    "        all_images = get_image_paths(ROOT_PATH, file_types=('.png'))\n",
    "    \"\"\"\n",
    "    # If the root path points to file, simply return it as a list with 1 element\n",
    "    if os.path.isfile(root_path):\n",
    "        return [root_path]\n",
    "    \n",
    "    # Gets all images in this root directory\n",
    "    all_images = []\n",
    "    for root, _junk, files in os.walk(root_path):\n",
    "        # Processes files in the root directory - can be transformed into a list\n",
    "        # comprehension but code might lose clarity\n",
    "        for file in files:\n",
    "            if file.lower().endswith(file_types):\n",
    "                exact_path = os.path.join(root, file)\n",
    "                all_images.append(exact_path)\n",
    "    \n",
    "    # Sort the image path list\n",
    "    if do_sort:\n",
    "        all_images.sort()\n",
    "\n",
    "    return all_images\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Creates a directory at the specified directory path 'dir_path' IF it does not\n",
    "  exist. Returns a status of 0 is the directory was successfully created and \n",
    "  returns a status of 1 if a directory already exists.\n",
    "\n",
    "  Inputs:\n",
    "    1. dir_path - directory path of new directory.\n",
    "    \n",
    "  Outputs:\n",
    "    1. status - 0 to indicate success (directory creation) or 1 to indicate\n",
    "       failure (directory already exists)\n",
    "    \n",
    "  Signature:\n",
    "    status = create_dir(dir_path)\n",
    "  \"\"\"\n",
    "  # Create directory\n",
    "  try:\n",
    "    os.makedirs(dir_path)\n",
    "    status = 0\n",
    "  except FileExistsError:\n",
    "    # Directory already exists\n",
    "    status = 1\n",
    "\n",
    "  return status\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def saved_verifier_exists(verifier_name, save_dir=SVD_VRF_DIR):\n",
    "    \"\"\"\n",
    "    Checks if a saved verifier exists with name 'verifier_name'. Does that by\n",
    "    comparing the 'verifier_name' against the name of all files in 'save_dir'.\n",
    "    \n",
    "    Inputs:\n",
    "        1. verifier_name - string with the name of the verifier.\n",
    "        2. save_dir - string with the full path of the save directory\n",
    "            ([save_dir=svd_vrf_dir]).\n",
    "        \n",
    "    Output:\n",
    "        1. Boolean value indicating if saved verifier exists or not.\n",
    "    \n",
    "    Signature:\n",
    "        verifier_exists = saved_verifier_exists(verifier_name,\n",
    "                                                save_dir=svd_vrf_dir)\n",
    "    \"\"\"\n",
    "    # Save directory provided is not a directory\n",
    "    if not os.path.isdir(save_dir):\n",
    "        return False\n",
    "    \n",
    "    # Otherwise, check if verifier name is in the names of files in the\n",
    "    # 'save_dir' directory\n",
    "    is_in = False\n",
    "    for file_name in os.listdir(save_dir):\n",
    "        is_in = is_in or verifier_name in file_name\n",
    "    \n",
    "    return is_in\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def save_face_verifiers(verifiers, save_dir=SVD_VRF_DIR, show_prog_bar=True,\n",
    "                        overwrite=False):\n",
    "    \"\"\"\n",
    "    Saves all face verifier models specified in 'verifiers' using the 'shelve'\n",
    "    (persistent storage) module. The models are saved in the 'save_dir'\n",
    "    directory and each model is saved individually. Models that fail to save (or\n",
    "    produces an error) are skipped. For each model that already exists, this\n",
    "    function does not overwrite it unless the 'overwrite' flag is set to True.\n",
    "    \n",
    "    Inputs:\n",
    "        1. verifiers - dictionary containing the build face verifier models.\n",
    "        2. show_prog_bar - boolean that toggles the progress bar on or off.\n",
    "        3. overwrite - boolean that indicates if the function should overwrite\n",
    "                        any saved models.\n",
    "                        \n",
    "    Outputs:\n",
    "        1. returns a status flag of True if any model fails to save (otherwise\n",
    "            returns False)\n",
    "    \n",
    "    Signature:\n",
    "        status = save_face_verifiers(verifiers, show_prog_bar=True,\n",
    "                    overwrite=False)\n",
    "    \"\"\"\n",
    "    # Checks if the save directory provided is a directory\n",
    "    if not os.path.isdir(save_dir):\n",
    "        return True\n",
    "    \n",
    "    # Creates the progress bar\n",
    "    n_verifiers    = len(verifiers)\n",
    "    disable_option = not show_prog_bar\n",
    "    pbar           = tqdm(range(0, n_verifiers), desc='Saving verifiers',\n",
    "                            disable = disable_option)\n",
    "    \n",
    "    # Loops through each verifier\n",
    "    no_errors_flag = False # False means no errors\n",
    "    for index, verifier_items in zip(pbar, verifiers.items()):\n",
    "        # Gets the name of the verifier and the verifier object\n",
    "        name     = verifier_items[0]\n",
    "        verifier = verifier_items[1]\n",
    "        \n",
    "        if not saved_verifier_exists(name, save_dir=save_dir) or overwrite:\n",
    "            try:\n",
    "                # Creates the file's full path\n",
    "                file_fp  = os.path.join(save_dir, name)\n",
    "        \n",
    "                # Opens a persistent dictionary, saves the model\n",
    "                # as a dictionary then closes it\n",
    "                with shelve.open(file_fp) as d:\n",
    "                    d[name]  = verifier\n",
    "            \n",
    "            except Exception as excpt:\n",
    "                no_errors_flag = True\n",
    "            \n",
    "    return no_errors_flag\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def load_face_verifier(verifier_names, save_dir=SVD_VRF_DIR,\n",
    "                        show_prog_bar=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Loads all face verifier models specified in 'verifier_names'. Alternatively,\n",
    "    'all' can be passed as a 'verifier_name' to load all saved models. The\n",
    "    models are loaded from the 'save_dir' directory.\n",
    "      \n",
    "    This function loads each model individually and skips any model that \n",
    "    fails to load (or produces an error).\n",
    "    \n",
    "    Inputs:\n",
    "        1. verifier_name - string with the name of the face verifiers.\n",
    "        2. save_dir      - string with the full path of the save directory\n",
    "            ([save_dir='']).\n",
    "        3. show_prog_bar - boolean that toggles the progress bar on or off.\n",
    "                        \n",
    "    Outputs:\n",
    "        1. returns a status flag of True if any model fails to save (otherwise\n",
    "            returns False)\n",
    "            \n",
    "    Signature:\n",
    "        models = load_face_verifier(verifier_names, save_dir='',\n",
    "                    show_prog_bar=True)\n",
    "    \"\"\"\n",
    "    # Checks if the save directory provided is a directory\n",
    "    if not os.path.isdir(save_dir):\n",
    "        raise OSError(f'Save directory does not exist ({save_dir})!')\n",
    "    \n",
    "    # Ensures that the verifier_names is a list (even a single name is provided)\n",
    "    if not isinstance(verifier_names, list):\n",
    "        verifier_names = [verifier_names]\n",
    "        \n",
    "    # If 'all' was provided, use all model names\n",
    "    if verifier_names[0].lower() == 'all':\n",
    "        verifier_names = ['VGG-Face', 'OpenFace', 'Facenet', 'Facenet512',\n",
    "                          'DeepFace', 'DeepID', 'ArcFace', 'Emotion', 'Age',\n",
    "                          'Gender', 'Race']\n",
    "    \n",
    "    # Creates the progress bar\n",
    "    n_verifiers    = len(verifier_names)\n",
    "    disable_option = not show_prog_bar\n",
    "    pbar           = tqdm(range(0, n_verifiers), desc='Loading verifiers',\n",
    "                            disable = disable_option)\n",
    "    \n",
    "    models = {}\n",
    "    for index, verifier_name in zip(pbar, verifier_names):       \n",
    "        # Checks if the face verifier model exists\n",
    "        if saved_verifier_exists(verifier_name, save_dir=save_dir):\n",
    "            # Loads the model\n",
    "            file_fp = os.path.join(save_dir, verifier_name)\n",
    "            with shelve.open(file_fp) as model:\n",
    "                if verbose:\n",
    "                    print(f'[load_face_verifier] Loading model',\n",
    "                          f'{verifier_name}: ', end='')\n",
    "                try:\n",
    "                    models[verifier_name] = model[verifier_name]\n",
    "                    if verbose:\n",
    "                        print('success!')\n",
    "                except Exception as excpt:\n",
    "                    if verbose:\n",
    "                        print(f'failed! Reason: {excpt}\\n',\n",
    "                               '[load_face_verifier] Attempting to build',\n",
    "                               ' & save model from scratch: ', sep='', end='')\n",
    "                    try:\n",
    "                        cur_model = build_verifier(verifier_name)\n",
    "                        models[verifier_name] = cur_model\n",
    "                        save_face_verifiers(cur_model, save_dir=save_dir,\n",
    "                                            show_prog_bar=False, overwrite=True)\n",
    "                        if verbose:\n",
    "                            print('success!')\n",
    "                    except Exception as excpt:\n",
    "                        if verbose:\n",
    "                            print(f'failed! Reason: {excpt}')\n",
    "                                \n",
    "        else:\n",
    "            # Otherwise, tries to build model from scratch & save it\n",
    "            if verbose:\n",
    "                print(f'[load_face_verifier] Model {verifier_name} ',\n",
    "                      'does not exist.', '\\nAttempting to build & save model ',\n",
    "                      'from scratch: ', sep='', end='')\n",
    "            try:\n",
    "                cur_model = build_verifier(verifier_name)\n",
    "                models[verifier_name] = cur_model\n",
    "                save_face_verifiers(cur_model, save_dir=save_dir,\n",
    "                                    show_prog_bar=False, overwrite=False)\n",
    "                if verbose:\n",
    "                    print('success!')\n",
    "            except Exception as excpt:\n",
    "                if verbose:\n",
    "                    print(f'failed! Reason: {excpt}')\n",
    "            \n",
    "    return models\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "        \n",
    "def load_representation_db(file_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Loads a database (at 'file_path') containing representations of face images.\n",
    "    The database is assumed to be a pickled Python object. The database is\n",
    "    expected to be a list of Representation object (see help(Representation)\n",
    "    for more information). If verbose is set to True, the loading processing is\n",
    "    printed, with any errors being reported to the user.\n",
    "\n",
    "    Inputs:\n",
    "        1. file_path - string with file's full path\n",
    "        2. verbose - flag indicating if the function should print information\n",
    "            about the loading process and errors ([verbose=False])\n",
    "\n",
    "    Output:\n",
    "        1. database object (list of Representation objects)\n",
    "    \n",
    "    Signature:\n",
    "        db = load_representation_db(file_path, verbose=False)\n",
    "    \"\"\"\n",
    "    # Prints message\n",
    "    if verbose:\n",
    "        print('Opening database: ', end='')\n",
    "\n",
    "    # Checks if path provided points to a valid database\n",
    "    if os.path.isfile(file_path):\n",
    "        # Try to open pickled database (list of objects)\n",
    "        try:\n",
    "            db = pickle.load(open(file_path, 'wb'))\n",
    "            if verbose:\n",
    "                print('success!')\n",
    "        \n",
    "        except (OSError, IOError) as e:\n",
    "            if verbose:\n",
    "                print(f'failed! Reason: {e}')\n",
    "            db = []\n",
    "\n",
    "    # If path does not point to a file, open an 'empty' database\n",
    "    else:\n",
    "        print(f'failed! Reason: database does not exist.')\n",
    "        db = []\n",
    "\n",
    "    return db\n",
    "                \n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def load_representation_db(file_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Loads a database (at 'file_path') containing representations of face images.\n",
    "    The database is assumed to be a pickled Python object. The database is\n",
    "    expected to be a list of Representation object (see help(Representation)\n",
    "    for more information). If verbose is set to True, the loading processing is\n",
    "    printed, with any errors being reported to the user.\n",
    "\n",
    "    Inputs:\n",
    "        1. file_path - string with file's full path\n",
    "        2. verbose - flag indicating if the function should print information\n",
    "            about the loading process and errors ([verbose=False])\n",
    "\n",
    "    Output:\n",
    "        1. database object (list of Representation objects)\n",
    "    \n",
    "    Signature:\n",
    "        db = load_representation_db(file_path, verbose=False)\n",
    "    \"\"\"\n",
    "    # Prints message\n",
    "    if verbose:\n",
    "        print('Opening database: ', end='')\n",
    "\n",
    "    # Checks if path provided points to a valid database\n",
    "    if os.path.isfile(file_path):\n",
    "        # Try to open pickled database (list of objects)\n",
    "        try:\n",
    "            db = pickle.load(open(file_path, 'wb'))\n",
    "            if verbose:\n",
    "                print('success!')\n",
    "        \n",
    "        except (OSError, IOError) as e:\n",
    "            if verbose:\n",
    "                print(f'failed! Reason: {e}')\n",
    "            db = []\n",
    "\n",
    "    # If path does not point to a file, open an 'empty' database\n",
    "    else:\n",
    "        print(f'failed! Reason: database does not exist.')\n",
    "        db = []\n",
    "\n",
    "    return db\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def detect_faces(img_path, detector_backend = 'opencv', align = True,\n",
    "                 return_type = 'both', face_detector = None):\n",
    "    \"\"\"\n",
    "    Detects faces in an image (and optionally aligns them).\n",
    "    \n",
    "    Inputs:\n",
    "        1. img_path - image path, base64 image or numpy array image\n",
    "        2. detector_backend - string corresponding to detector ([opencv],\n",
    "            ssd, dlib, mtcnn, retinaface, mediapipe).\n",
    "        3. align - flag indicating if face should be aligned ([align=True]).\n",
    "        4. return_type - string indicating if faces, regions or both should\n",
    "            be returned ('faces', 'regions', ['both']).\n",
    "            \n",
    "    Outputs:\n",
    "        If return_type='regions':\n",
    "            Dictionary containing list of face detections. The face detections\n",
    "            (or regions of interest - rois) are lists with the format\n",
    "            [top-left x, top-left y, width, height]. The dictionary key is\n",
    "            'regions'.\n",
    "            \n",
    "        If return_type='faces':\n",
    "            Dictionary containing list of detected faces. Each detection is an\n",
    "            image with 'target_size' size (the number of color channels is\n",
    "            unchanged). The dictionary key is 'faces'.\n",
    "            \n",
    "        If return_type='both':\n",
    "            Dictionary containing both of the above outputs: face detections and\n",
    "            detected faces. The dictionary keys are 'faces' and 'regions'. \n",
    "    \n",
    "    Signature:\n",
    "        output = detect_faces(img_path, detector_backend = 'opencv',\n",
    "                              align = True, return_type = 'both')\n",
    "    \"\"\"\n",
    "    # Raises an error if return type is not 'faces', 'regions' or 'both'.\n",
    "    # Otherwise, initializes lists.\n",
    "    if return_type == 'faces' or return_type == 'regions' or \\\n",
    "        return_type == 'both':\n",
    "        faces = []\n",
    "        rois  = []\n",
    "    else:\n",
    "        raise ValueError(\"Return type should be 'faces', 'regions' or 'both'.\")\n",
    "    \n",
    "    # Loads image. Image might be path, base64 or numpy array. Convert it to numpy\n",
    "    # whatever it is.\n",
    "    img = functions.load_image(img_path)\n",
    "\n",
    "    # The detector is stored in a global variable in FaceDetector object.\n",
    "    # This call should be completed very fast because it will return found in\n",
    "    # memory and it will not build face detector model in each call (consider for\n",
    "    # loops)\n",
    "    if face_detector == None:\n",
    "        face_detector = FaceDetector.build_model(detector_backend)\n",
    "    detections = FaceDetector.detect_faces(face_detector, detector_backend,\n",
    "                                            img, align)\n",
    "\n",
    "    # Prints a warning and returns an empty dictionary and error if no faces were\n",
    "    # found, otherwise processes faces & regions\n",
    "    if len(detections) == 0:\n",
    "        print('Face could not be detected or the image contains no faces.')\n",
    "\n",
    "    else:\n",
    "        # Loops through each face & region pair\n",
    "        for face, roi in detections:\n",
    "\n",
    "            # Only process images (faces) if the return type is 'faces' or 'both'\n",
    "            if return_type == 'faces' or return_type == 'both':\n",
    "                # Appends processed face\n",
    "                faces.append(face)\n",
    "    \n",
    "            # Only process regions (rois) if the return type is 'regions' or 'both'\n",
    "            if return_type == 'regions' or return_type == 'both':\n",
    "                rois.append(roi)\n",
    "\n",
    "  # ------------------------\n",
    "  \n",
    "    if return_type == 'faces':\n",
    "        return {'faces':faces}\n",
    "    elif return_type == 'regions':\n",
    "        return {'regions':rois}\n",
    "    else:\n",
    "        assert return_type == 'both', \"Return type should be 'both' here.\"\n",
    "        return {'faces':faces, 'regions':rois}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def process_face(img_path, target_size=(224, 224), normalization='base',\n",
    "                    grayscale=False):\n",
    "    \"\"\"\n",
    "    Applies some processing to an image of a face:\n",
    "        1. Loads the image from an image path, base64 encoding or numpy array\n",
    "        2. If the 'grayscale' flag is True, converts the image to grayscale\n",
    "        3. Resizes the image based on the smallest factor (target_size /\n",
    "            dimension) and zero pads the resized image to match the target size.\n",
    "        4. If for some reason the image is still not the target size, resizes\n",
    "            the modified image once again.\n",
    "        5. Normalizes the image based on the normalization option:\n",
    "            a. 'base': do nothing\n",
    "            b. 'raw': restore input in scale of [0, 255]\n",
    "            c. 'Facenet': 'raw' then subtract image mean and divide by image\n",
    "                    standard deviation\n",
    "            d. 'Facenet2018': 'raw' then divide by 127.5 and subtract 1\n",
    "            e. 'VGGFace': 'raw' then mean subtraction based on VGGFace1 training\n",
    "                    data\n",
    "            f. 'VGGFace2': 'raw' then mean subtraction based on VGGFace2\n",
    "                    training data\n",
    "            g. 'ArcFace': based on a reference study, 'raw', then pixels are\n",
    "                    normalized by subtracting 127.5 then dividing by 128.\n",
    "\n",
    "    Inputs:\n",
    "        1. img_path - image path, base64 image or numpy array\n",
    "        2. target_size - tuple containing desired X and Y dimensions\n",
    "            ([target_size=(224, 224)])\n",
    "        3. normalization - defines a type of normalization\n",
    "            ([normalization='base'])\n",
    "        4. grayscale - flag indicating if image should be converted to grayscale\n",
    "            ([grayscale=False])\n",
    "\n",
    "    Output:\n",
    "        1. processed image as a numpy array\n",
    "\n",
    "    Signature:\n",
    "        face_image = process_face(img_path, target_size=(224, 224),\n",
    "                                  normalization='base', grayscale=False)\n",
    "    \"\"\"\n",
    "    # Loads the face image. Image might be path, base64 or numpy array. Convert\n",
    "    # it to numpy whatever it is.\n",
    "    face = functions.load_image(img_path)\n",
    "    \n",
    "    # Ensures that both dimensions are >0, otherwise raises error\n",
    "    if face.shape[0] == 0 or face.shape[1] == 0:\n",
    "        raise ValueError(f'Detected face shape is {face.shape}.')\n",
    "\n",
    "    # Converts to grayscale if face is \n",
    "    if grayscale:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "    # Resizes face\n",
    "    if face.shape[0] > 0 and face.shape[1] > 0:\n",
    "        factor_0 = target_size[0] / face.shape[0]\n",
    "        factor_1 = target_size[1] / face.shape[1]\n",
    "        factor   = min(factor_0, factor_1)\n",
    "\n",
    "    dsize  = (int(face.shape[1] * factor), int(face.shape[0] * factor))\n",
    "    face   = cv2.resize(face, dsize)\n",
    "\n",
    "    # Then pad the other side to the target size by adding black pixels\n",
    "    diff_0 = target_size[0] - face.shape[0]\n",
    "    diff_1 = target_size[1] - face.shape[1]\n",
    "                \n",
    "    if not grayscale:\n",
    "        # Put the base image in the middle of the padded image\n",
    "        face = np.pad(face, ((diff_0 // 2, diff_0 - diff_0 // 2),\n",
    "                             (diff_1 // 2, diff_1 - diff_1 // 2), (0, 0)),\n",
    "                             'constant')\n",
    "    else:\n",
    "        face = np.pad(face, ((diff_0 // 2, diff_0 - diff_0 // 2),\n",
    "                             (diff_1 // 2, diff_1 - diff_1 // 2)),\n",
    "                             'constant')\n",
    "\n",
    "    # Double check if target image is not still the same size with target.\n",
    "    if face.shape[0:2] != target_size:\n",
    "        face = cv2.resize(face, target_size)\n",
    "\n",
    "    # Normalizing the image pixels\n",
    "    if normalization == 'base':\n",
    "        face  = image.img_to_array(face) #what this line doing? must?\n",
    "        face  = np.expand_dims(face, axis = 0)\n",
    "        face /= 255 # normalize input in [0, 1]\n",
    "    else:\n",
    "        face = functions.normalize_input(face, normalization=normalization)\n",
    "    \n",
    "    return face\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calc_cosine_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity metric between matrices A and B. If A is a\n",
    "    vector, it is converted into a matrix so that the cosine metric can be\n",
    "    calculated normally.\n",
    "\n",
    "    Inputs:\n",
    "        1. A - N x M matrix with N embeddings with M elements\n",
    "        2. A - I x M matrix with I embeddings with M elements\n",
    "\n",
    "    Outputs:\n",
    "        1. matrix of cosine similarity metric between A and B\n",
    "\n",
    "    Signature:\n",
    "        csm = calc_cosine_similarity(A, B)\n",
    "    \"\"\"\n",
    "    if A.ndim == 1:\n",
    "        A = A[np.newaxis, :]\n",
    "\n",
    "    num = np.dot(A, B.T)\n",
    "    p1  = np.sqrt(np.sum(A**2, axis=1))[:, np.newaxis]\n",
    "    p2  = np.sqrt(np.sum(B**2, axis=1))[np.newaxis, :]\n",
    "    return 1 - (num / (p1 * p2))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calc_euclidean_similarity(A, B, l2_normalize=False):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean similarity metric between matrices A and B. If A is\n",
    "    a vector, it is converted into a matrix by repeating (and stacking) it\n",
    "    horizontally until it has the correct dimensions. If 'l2_normalize' is set\n",
    "    to True, then the function applies L2 normalization to the inputs before\n",
    "    calculating the Euclidean similarity (distance).\n",
    "\n",
    "    Inputs:\n",
    "        1. A - N x M matrix with N embeddings with M elements\n",
    "        2. A - I x M matrix with I embeddings with M elements\n",
    "        3. l2_normalize - boolean to indicate if the inputs should be L2\n",
    "            normalized before calculating the similarity ([l2_normalize=True])\n",
    "\n",
    "    Outputs:\n",
    "        1. matrix of Euclidean similarity metric between A and B\n",
    "\n",
    "    Signature:\n",
    "        edm = calc_euclidean_similarity(A, B, l2_normalize=False)\n",
    "    \"\"\"\n",
    "    # Applies l2 normalization to the inputs if necessary\n",
    "    if l2_normalize:\n",
    "        if A.ndim == 1:\n",
    "            A = A / np.sqrt(np.sum(np.multiply(A, A)))\n",
    "        else:\n",
    "            A = np.transpose(A.T / np.linalg.norm(A, axis=1))\n",
    "\n",
    "        if B.ndim == 1:\n",
    "            B = B / np.sqrt(np.sum(np.multiply(B, B)))\n",
    "        else:\n",
    "            B = np.transpose(B.T / np.linalg.norm(B, axis=1))\n",
    "\n",
    "    # 'Repeats vertically' vector A until it is a matrix with appropriate\n",
    "    # dimensions \n",
    "    if A.ndim == 1:\n",
    "        A = np.tile(A, (B.shape[0], 1))\n",
    "\n",
    "    # Calcultes and returns the Euclidean distance\n",
    "    return np.sqrt(np.sum((A - B) * (A - B), axis=1))\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calc_similarity(tgt_embd, embds, metric='cosine', model_name='VGG-Face',\n",
    "                    threshold=-1):\n",
    "    \"\"\"\n",
    "    Calculates the similarity (distance) between both embeddings ('tgt_embd'\n",
    "    and 'embds') using the 'metric' distance metric. If the 'threshold' < 0 then\n",
    "    it is automatically determined based on the 'model_name' provided. If a \n",
    "    custom threshold is specified, then the 'model_name' input is unused.\n",
    "\n",
    "    Note that 'embds' can be a N x M matrix (N embeddings each with M elements)\n",
    "    and 'tgt_embd' can only be a 1 x M embedding.\n",
    "\n",
    "    Inputs:\n",
    "        1. tgt_embd - 1-D numpy array containing the embedding.\n",
    "        2. embds - 1-D or 2-D numpy array containing the embedding(s).\n",
    "        3. metric - string specifying the distance metric to be used\n",
    "            (['cosine'], 'euclidean', 'l2_euclidean').\n",
    "        4. model_name - string specifying the model name (['VGG-Face']).\n",
    "        5. threshold - if a negative float is provided, then the threshold is\n",
    "            calculated automatically based on the model name provided.\n",
    "            Otherwise, the threshold provided is used ([threshold=-1]).\n",
    "\n",
    "    Output:\n",
    "        1. dictionary containing the indexes of matches (key: idxs), the\n",
    "            threshold value used (key: threshold) and the distances (using the\n",
    "            specified metric) of the matches (key: distances). Note that if no\n",
    "            match is found, then the 'indexes' will have a length of zero (i.e.\n",
    "            will be empty).\n",
    "    \n",
    "    Signature:\n",
    "        similarity_obj = calc_similarity(tgt_embd, embds, metric='cosine',\n",
    "                                         model_name='VGG-Face', threshold=-1)\n",
    "    \"\"\"\n",
    "    # Calculates the distance based on the metric provided, otherwise raises a\n",
    "    # value error\n",
    "    if metric == 'cosine':\n",
    "        distances = calc_cosine_similarity(tgt_embd, embds)\n",
    "    elif metric == 'euclidean':\n",
    "        distances = calc_euclidean_similarity(tgt_embd, embds)\n",
    "    elif metric == 'euclidean_l2':\n",
    "        distances = calc_euclidean_similarity(tgt_embd, embds,\n",
    "                                              l2_normalize=True)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid metric passed: {metric}')\n",
    "\n",
    "    # If threshold is negative, determine threshold automatically based on the\n",
    "    # model name and distance metric\n",
    "    if threshold < 0:\n",
    "        threshold = dst.findThreshold(model_name, metric)\n",
    "    \n",
    "    # Processes distances\n",
    "    distances = distances.flatten() # flattens into 1-D array\n",
    "\n",
    "    # Makes a decision\n",
    "    decision  = (distances <= threshold)\n",
    "    idxs      = np.where(decision)[0]\n",
    "\n",
    "    # Determines the corresponding distances of each match (decision==True)\n",
    "    dists = []\n",
    "    j     = 0\n",
    "    for i in range(len(distances)):\n",
    "        if i in idxs:\n",
    "            dists.append(distances[i])\n",
    "            j += 1\n",
    "        \n",
    "        if j == len(idxs):\n",
    "            break\n",
    "\n",
    "    # Sort the indexes by smallest distance\n",
    "    srt_dists = []\n",
    "    srt_idxs  = []\n",
    "    for dist, idx in sorted(zip(dists, idxs)):\n",
    "        srt_idxs.append(idx)\n",
    "        srt_dists.append(dist)\n",
    "\n",
    "    return {'idxs': np.array(srt_idxs),\n",
    "            'threshold': threshold,\n",
    "            'distances': np.array(srt_dists)}\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def calc_embedding(img_path, verifier_models, detector_name='opencv',\n",
    "                    align=True, verifier_names='VGG-Face',\n",
    "                    normalization='base'):\n",
    "    \"\"\"\n",
    "    TODO: ADD DESCRIPTION\n",
    "    \"\"\"\n",
    "    # Converts verifier names into a list if it is a single entry\n",
    "    if not isinstance(verifier_names, list):\n",
    "        verifier_names = [verifier_names]\n",
    "\n",
    "    # Tries to detect faces & align:\n",
    "    try:\n",
    "        output = detect_faces(img_path, detector_backend=detector_name,\n",
    "                                align=align, return_type='both',\n",
    "                                face_detector=None)\n",
    "    except:\n",
    "        print('[calc_embedding] Error: face detection failed!')\n",
    "        return ([], {})\n",
    "\n",
    "    # TODO: MAKE THE FUNCTION ACCEPT MULTIPLE FACES IN ONE IMAGE\n",
    "    # Since we assume there is only 1 face (and region):\n",
    "    face   = output['faces'][0]\n",
    "    region = output['regions'][0]\n",
    "\n",
    "    # For each verifier model provided\n",
    "    embeddings={}\n",
    "    for verifier_name in verifier_names:\n",
    "        # Gets the current verifier model\n",
    "        model = verifier_models[verifier_name]\n",
    "\n",
    "        # Determine target size\n",
    "        input_x, input_y = functions.find_input_shape(model)\n",
    "\n",
    "        # Process face\n",
    "        processed_face = process_face(face, target_size=(input_x, input_y),\n",
    "                                normalization=normalization, grayscale=False)\n",
    "\n",
    "        # Calculate embeddings\n",
    "        embeddings[verifier_name] = model.predict(processed_face)[0]\n",
    "\n",
    "    return (region, embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_new_representation(img_path, region, embeddings, tag='', uid='',\n",
    "                                ignore_taglist=['--', '---']):\n",
    "\n",
    "    # If Unique IDentifier (UID) is not provided, generate one\n",
    "    if len(uid) == 0 or uid == '':\n",
    "        uid = uuid4()\n",
    "\n",
    "    # If tag is in the ignore taglist, then it is considered as a \"ignore\" tag\n",
    "    if tag in ignore_taglist:\n",
    "        tag = ''\n",
    "\n",
    "    # Returns the new representation\n",
    "    return Representation(uid, image_name=img_path.split('/')[-1], \n",
    "                          image_fp=img_path, name_tag=tag, region=region,\n",
    "                          embeddings=embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def get_embeddings_as_array(db, verifier_name):\n",
    "    \"\"\"\n",
    "    Gets all of the embeddings for a given 'verifier_name' from the database\n",
    "    'db' and returns it as a N x M numpy array where N is the number of\n",
    "    embeddings and M is the number of elements of each embeddings.\n",
    "\n",
    "    Inputs:\n",
    "        1. db - database object (list of Representation objects)\n",
    "        2. verifier_name - name of verifier\n",
    "\n",
    "    Output:\n",
    "        1. N x M numpy array where each row corresponds to a face image's\n",
    "            embedding\n",
    "\n",
    "    Signature:\n",
    "        embeddings = get_embeddings_as_array(db, verifier_name)\n",
    "    \"\"\"\n",
    "    embeddings = [] # initializes empty list\n",
    "    for rep in db:\n",
    "        embeddings.append(rep.embeddings[verifier_name])\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def person_name_lookup(img_paths):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    name_list = []\n",
    "    for pth in img_paths:\n",
    "        cur_num = int(pth.split('/')[-1][3:5])\n",
    "\n",
    "        if cur_num   in [ 1,  2,  4,  5,  6,  7, 10, 11]:   # Angelina Jolie\n",
    "            name_list.append('Angelina Jolie')\n",
    "        \n",
    "        elif cur_num in [ 3, 12, 53, 54, 55, 56]:           # Jennifer Aniston\n",
    "            name_list.append('Jennifer Aniston')\n",
    "\n",
    "        elif cur_num in [ 8,  9, 47, 48, 49, 50, 51]:       # Scarlett Johansson\n",
    "            name_list.append('Scarlett Johansson')\n",
    "\n",
    "        elif cur_num in [13, 14, 15, 57, 58]:               # Mark Zuckerberg\n",
    "            name_list.append('Mark Zuckerberg')\n",
    "\n",
    "        elif cur_num in [16, 17, 59, 61, 62]:               # Jack Dorsey\n",
    "            name_list.append('Jack Dorsey')\n",
    "\n",
    "        elif cur_num in [18, 19, 67]:                       # Elon Musk\n",
    "            name_list.append('Elon Musk')\n",
    "\n",
    "        elif cur_num in [20, 21]:                           # Jeff Bezos\n",
    "            name_list.append('Jeff Bezos')\n",
    "\n",
    "        elif cur_num in [22, 23]:                           # Marissa Meyer\n",
    "            name_list.append('Marissa Meyer')\n",
    "\n",
    "        elif cur_num in [24, 25]:                           # Sundar Pichai\n",
    "            name_list.append('Sundar Pichai')\n",
    "        \n",
    "        elif cur_num in [26, 27, 28, 42, 43, 44, 45, 46]:   # Katy Perry\n",
    "            name_list.append('Katy Perry')\n",
    "\n",
    "        elif cur_num in [29, 30, 31, 32, 33]:               # Matt Damon\n",
    "            name_list.append('Matt Damon')\n",
    "\n",
    "        elif cur_num in [34, 35, 36, 37]:                   # Leonardo DiCaprio\n",
    "            name_list.append('Leonardo DiCaprio')\n",
    "\n",
    "        elif cur_num in [38, 39, 40, 41]:                   # George Clooney\n",
    "            name_list.append('George Clooney')\n",
    "\n",
    "        else:\n",
    "            name_list.append('')                            # missing name\n",
    "\n",
    "    return name_list\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_reps_from_dir(img_dir, verifier_models, detector_name='opencv',\n",
    "                    align=True, verifier_names='VGG-Face', show_prog_bar=True,\n",
    "                    normalization='base', tags=[], uids=[], skip_get_imgs=False,\n",
    "                    verbose=False):\n",
    "    \"\"\"\n",
    "    Creates a representations from images in a directory 'img_dir'. The\n",
    "    representations are returned in a list, and the list of representations. If\n",
    "    tags and/or unique identifiers (uids) are provided, make sure that they \n",
    "    correspond to the sorted (ascending) image names contained in 'img_dir'.\n",
    "\n",
    "    Inputs:\n",
    "        1. img_dir - string with the full path to the directory containing the\n",
    "            images.\n",
    "\n",
    "        2. verifier_models - dictionary containing model name (key) and model\n",
    "            object (value).\n",
    "\n",
    "        3. detector_name - string with the face detector name ([opencv], ssd,\n",
    "            dlib, mtcnn, retinaface).\n",
    "        \n",
    "        4. align - boolean flag to indicate if face images should be aligned.\n",
    "            Improves face recognition performance at the cost of some speed\n",
    "            ([True], False).\n",
    "\n",
    "        5. verifier_names - string with the face verifier name ([VGG-Face],\n",
    "            OpenFace, Facenet, Facenet512, DeepFace, DeepID, ArcFace).\n",
    "\n",
    "        6. show_prog_bar - boolean that toggle the progress bar on or off\n",
    "            ([True], False).\n",
    "\n",
    "        7. normalization - normalizes the face image and may increase face\n",
    "            recognition performance depending on the normalization type and the\n",
    "            face verifier model ([base], raw, Facenet, Facenet2018, VGGFace,\n",
    "            VGGFace2, ArcFace).\n",
    "\n",
    "        8. tags - list of strings where each string corresponds to a tag for the\n",
    "            i-th image, i.e. tags[0] is the tag for the first image in the\n",
    "            sorted list of image name obtain from 'img_dir' directory. If an\n",
    "            empty list is provided, this is skipped during the representation\n",
    "            creation process ([tags=[]]).\n",
    "\n",
    "        9. uids - list of strings where each string corresponds to a unique\n",
    "            identifier (UID) for the i-th image, i.e. uids[0] is the UID for the\n",
    "            first image in the sorted list of image name obtain from 'img_dir'\n",
    "            directory. If an empty list is provided, a UID is created for each\n",
    "            image during the representation creation process ([uids=[]]).\n",
    "\n",
    "        10. skip_get_imgs - boolean to skip getting the image paths from the\n",
    "            directory. This should be set to True if a list of image paths is\n",
    "            provided as 'img_dir' as opposed to a directory\n",
    "            ([skip_get_imgs=False]).\n",
    "            \n",
    "        11. verbose - boolean to toggle function warnings and other messages\n",
    "            ([True], False).\n",
    "\n",
    "        Note: the 'tags' and 'uids' lists (inputs 8 and 9) must have the same\n",
    "        number of elements (length) and must match the number of images in\n",
    "        'img_dir'. If not, these inputs will be treated as empty lists (i.e.\n",
    "        ignored).\n",
    "\n",
    "    Outputs:\n",
    "        1. list of Representation objects. For more information about the\n",
    "            Representation class attributes and methods, use\n",
    "            help(Representation)\n",
    "\n",
    "    Signature:\n",
    "        rep_db = create_reps_from_dir(img_dir, verifier_models, \n",
    "                        detector_name='opencv', align=True,\n",
    "                        verifier_names='VGG-Face', show_prog_bar=True,\n",
    "                        normalization='base', tags=[], uids=[], verbose=False)\n",
    "    \"\"\"\n",
    "    # Initializes skip flags and database (list of Representation objects)\n",
    "    skip_tag = False\n",
    "    skip_uid = False\n",
    "    rep_db   = []\n",
    "    \n",
    "    # Assuming img_dir is a directory containing images\n",
    "    if not skip_get_imgs:\n",
    "        img_paths = get_image_paths(img_dir)\n",
    "        img_paths.sort()\n",
    "    else:\n",
    "        img_paths = img_dir\n",
    "\n",
    "    # No images found, return empty database\n",
    "    if len(img_paths) == 0:\n",
    "        return []\n",
    "\n",
    "    # If tags list does not have the same number of elements as the images (i.e.\n",
    "    # 1 tag per image), ignore it\n",
    "    if len(tags) != len(img_paths):\n",
    "        if verbose:\n",
    "            print('[create_reps_from_dir] Number of tags and image paths',\n",
    "                  'must match. Ignoring tags list.')\n",
    "        skip_tag = True\n",
    "\n",
    "    # If uids list does not have the same number of elements as the images (i.e.\n",
    "    # 1 UID per image), ignore it\n",
    "    if len(uids) != len(img_paths):\n",
    "        if verbose:\n",
    "            print('[create_reps_from_dir] Number of UIDs and image paths',\n",
    "                  'must match. Ignoring uids list.')\n",
    "        skip_uid = True\n",
    "\n",
    "    # Creates the progress bar\n",
    "    n_imgs  = len(img_paths)\n",
    "    disable = not show_prog_bar\n",
    "    pbar    = tqdm(range(0, n_imgs), desc='Creating representations',\n",
    "                    disable=disable)\n",
    "\n",
    "    # Loops through each image in the 'img_dir' directory\n",
    "    for pb_idx, i, img_path in zip(pbar, range(0, n_imgs), img_paths):\n",
    "        # Calculate the face image embedding\n",
    "        region, embeddings = calc_embedding(img_path, verifier_models,\n",
    "                                            align=align,\n",
    "                                            detector_name=detector_name, \n",
    "                                            verifier_names=verifier_names,\n",
    "                                            normalization=normalization)\n",
    "\n",
    "        # Determines if tag was provided and should be used when creating this\n",
    "        # representation\n",
    "        if skip_tag:\n",
    "            tag = ''\n",
    "        else:\n",
    "            tag = tags[i]\n",
    "\n",
    "        # Determines if UID was provided and should be used when creating this\n",
    "        # representation\n",
    "        if skip_uid:\n",
    "            uid = ''\n",
    "        else:\n",
    "            uid = uids[i]\n",
    "\n",
    "        # Create a new representation and adds it to the database\n",
    "        rep_db.append(create_new_representation(img_path, region, embeddings,\n",
    "                                                tag=tag, uid=uid))\n",
    "\n",
    "    # Return representation database\n",
    "    return rep_db\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def find_image_in_db(img_path, db, shortcut=None):\n",
    "    \"\"\"\n",
    "    Finds the corresponding Representation in the database 'db'. Uses the\n",
    "    image's name obtained from its full path ('img_path') to match the\n",
    "    Representation to the image. An optional dictionary ('shortcut') can be\n",
    "    provided where each letter corresponds to an index to speed up the search.\n",
    "    Consider a sorted database where the first image with a name starting with\n",
    "    a 'g' is at position 156. Then a shortcut dictionary with the key/value pair\n",
    "    'g':155 will ensure this function starts at the position 156 and wont waste\n",
    "    time previous database entries.\n",
    "\n",
    "    Inputs:\n",
    "        1. img_path - image path, base64 image or numpy array\n",
    "        2. db - database object (list of Representation objects)\n",
    "        3. shortcut - optional dictionary with letter/index key/value pairs\n",
    "            ([shortcut=None])\n",
    "\n",
    "    Output:\n",
    "        1. tuple containing the matching Representation object and the index\n",
    "            corresponding to that object in the database (i.e. output\n",
    "            representation == database[output index]). If no match is found,\n",
    "            both representation and index are returned as empty lists. If\n",
    "            multiple entries are found, multiple Representations and indexs are\n",
    "            returned as lists.\n",
    "    \"\"\"\n",
    "    rep_objs = [] # empty representation object\n",
    "    rep_idxs = [] # no matching index\n",
    "\n",
    "    # Database is empty\n",
    "    if len(db) == 0:\n",
    "        pass # do nothing\n",
    "\n",
    "    # 'shortcut' dictionary is provided\n",
    "    elif not shortcut == None:\n",
    "        # Get image name\n",
    "        img_name = img_path.split('/')[-1].lower()\n",
    "        idx      = shortcut[img_name[0]]\n",
    "\n",
    "        # \n",
    "        for i, rep in enumerate(db[idx::]):\n",
    "            if img_name.lower() == rep.image_name:\n",
    "                rep_objs.append(rep)\n",
    "                rep_idxs.append(i + idx)\n",
    "\n",
    "    # 'shortcut' dictionary is not provided\n",
    "    else:\n",
    "        # Get image name\n",
    "        img_name = img_path.split('/')[-1].lower()\n",
    "\n",
    "        # \n",
    "        for i, rep in enumerate(db):\n",
    "            if img_name.lower() == rep.image_name:\n",
    "                rep_objs.append(rep)\n",
    "                rep_idxs.append(i)\n",
    "\n",
    "    return (rep_objs, rep_idxs)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def create_faiss_index(embeddings, metric='cosine'):\n",
    "    \"\"\"\n",
    "    Create faiss indexes from 'embeddings'. Embeddings are expected to be a\n",
    "    N x M numpy array with N embeddings each with M elements.\n",
    "\n",
    "    Inputs:\n",
    "        1. embeddings - N x M numpy array\n",
    "        2. metric - string specifying the distance/similarity metric ([cosine],\n",
    "            euclidean, euclidean_l2)\n",
    "\n",
    "    Output:\n",
    "        1. index object with embeddings added\n",
    "\n",
    "    Signature:\n",
    "        index = create_faiss_index(embeddings, metric='cosine')\n",
    "    \"\"\"\n",
    "    # Create the appropriate index based on the distance metric provided. If the\n",
    "    # distance metric provided is not valid (not cosine, euclidean or\n",
    "    # euclidean_l2), an error is raised.\n",
    "    if metric == 'cosine':\n",
    "        index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "    elif metric in ['euclidean', 'euclidean_l2']:\n",
    "        index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    else:\n",
    "        raise ValueError(f'{metric} is an invalid metric!',\n",
    "                          'Expected cosine, euclidean or euclidean_l2.',\n",
    "                          sep='\\n')\n",
    "    \n",
    "    # Applies L2 normalization in the cases of cosine or euclidean_l2 metrics\n",
    "    if metric in ['cosine', 'euclidean_l2']:\n",
    "        embeddings = dst.l2_normalize(embeddings)\n",
    "\n",
    "    # Adds the embeddings to the index object\n",
    "    index.add(embeddings)\n",
    "\n",
    "    return index\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def verify_with_faiss(target_embd, index, db, top_x=3, model_name='VGG-Face',\n",
    "                      metric='cosine', threshold=-1):\n",
    "    \"\"\"\n",
    "    Uses the Faiss library to speed up the verification process. The 'index'\n",
    "    object is a faiss-specific object with the embeddings of the whole database\n",
    "    'db'. Using faiss fast search, the 'top_x' nearest neighbour embeddings are\n",
    "    obtained and are used to create a subset of the original database.\n",
    "\n",
    "    The similarity (and matches) are then calculated using the subset database,\n",
    "    which is only 'top_x' large. Note that the speed gains are more noticeable\n",
    "    for larger databases and small values of 'top_x'. Also note that if there\n",
    "    are more than 'top_x' matches, then only 'top_x' will be returned.\n",
    "\n",
    "    Finally, if top_x = 1 then this function returns the nearest neighbour match\n",
    "    and the 'model_name' and 'threshold' parameters have no effect. In this\n",
    "    case, the threshold value in the output dictionary will be equal to -1 to\n",
    "    indicate it has not been used.\n",
    "\n",
    "    Inputs:\n",
    "        1. target_embd - 1-D numpy array containing the embedding.\n",
    "        2. index - faiss-specific index object. Use 'load_faiss_indexes'\n",
    "                function to create it.\n",
    "        3. db - database (list of Representation objects)\n",
    "        4. top_x - natural number indicating the number of nearest neighbours to\n",
    "                filter the database ([top_x=3])\n",
    "        5. model_name - string specifying the model name (['VGG-Face']).\n",
    "        6. metric - string specifying the distance metric to be used\n",
    "                (['cosine'], 'euclidean', 'l2_euclidean').\n",
    "        7. threshold - if a negative float is provided, then the threshold is\n",
    "                calculated automatically based on the model name provided.\n",
    "                Otherwise, the threshold provided is used ([threshold=-1]).\n",
    "    \n",
    "    Output:\n",
    "        1. dictionary containing the indexes of matches (key: idxs), the\n",
    "            threshold value used (key: threshold) and the distances calculated\n",
    "            using the specified metric (key: distances). Note that if no match\n",
    "            is found, then the 'indexes' will have a length of zero (i.e. will\n",
    "            be empty). The indexes and distances are sorted so that the first\n",
    "            index has the smallest distance, the second index has the second\n",
    "            smallest distance, and so on.\n",
    "\n",
    "    Signature:\n",
    "        similarity_obj = verify_with_faiss(target_embd, index, db, top_x=3,\n",
    "                                    model_name='VGG-Face', metric='cosine',\n",
    "                                    threshold=-1)\n",
    "    \"\"\"\n",
    "    # Obtains the 'top_x' nearest neighbours\n",
    "    distances, neighbors = index.search(target_embd, top_x)\n",
    "\n",
    "    # If top_x is 1 then simply return the closest neighbour\n",
    "    if top_x == 1:\n",
    "        similarity_obj['idxs']      = np.array(neighbors[0], dtype=int)\n",
    "        similarity_obj['threshold'] = -1\n",
    "        similarity_obj['distances'] = distances\n",
    "        return similarity_obj\n",
    "\n",
    "    # Obtains the embeddings for the 'filtered' (top_x) representations\n",
    "    idxs          = []\n",
    "    filtered_reps = []\n",
    "    for i in np.array(neighbors[0], dtype=int):\n",
    "        idxs.append(i)\n",
    "        filtered_reps.append(db[i])\n",
    "\n",
    "    embds = get_embeddings_as_array(filtered_reps, model_name)\n",
    "\n",
    "    # Calculates the matches to the target embedding (from the top_x filtered\n",
    "    # set of representations)\n",
    "    similarity_obj = calc_similarity(target_embd, embds, metric=metric,\n",
    "                                     model_name=model_name, threshold=threshold)\n",
    "\n",
    "    # Note that the indexes returned in the similarity object refer to the\n",
    "    # filtered representations. So the correct indexes (from the original\n",
    "    # database) are actually the idxs[similarity_obj['idxs']]\n",
    "    similarity_obj['idxs'] = [idxs[i] for i in similarity_obj['idxs']]\n",
    "\n",
    "    return similarity_obj\n",
    "\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Directory creation:\n",
      "Creating /home/rpessoa/projects/loki/api directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/data directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/data/raw directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/data/targets directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/data/database directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/saved_models directory: directory exists. Continuing...\n",
      "Creating /home/rpessoa/projects/loki/api/saved_models/verifiers directory: directory exists. Continuing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All detectors and verifiers\n",
    "DETECTOR_NAMES = ('opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface')\n",
    "VERIFIER_NAMES = ('VGG-Face', 'OpenFace', 'Facenet', 'Facenet512', 'DeepFace',\n",
    "                  'DeepID', 'Dlib', 'ArcFace', 'Emotion', 'Age', 'Gender',\n",
    "                  'Race')\n",
    "\n",
    "# Directories & paths initialization\n",
    "print('  -> Directory creation:')\n",
    "for directory in directory_list:\n",
    "    print(f'Creating {directory} directory: ', end='')\n",
    "    \n",
    "    if create_dir(directory):\n",
    "        print('directory exists. Continuing...')\n",
    "    else:\n",
    "        print('success.')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model   = 'ArcFace'\n",
    "chosen_backend = 'retinaface'\n",
    "align          = True\n",
    "normalization  = 'base'\n",
    "metric         = 'cosine'\n",
    "use_faiss      = True\n",
    "top_x          = 10\n",
    "threshold      = -1 # automatically get threshold based on chosen model & metric\n",
    "\n",
    "# Paths\n",
    "dataset_path      = ''\n",
    "stored_imgs_path  = '/' + os.path.join(*(API_DIR.split('/')[:-1]), 'dataset')\n",
    "db_path           = '' # no database exists\n",
    "svd_verifier_path = SVD_VRF_DIR\n",
    "\n",
    "# Splits\n",
    "db_split  = [ 5,  6,  8, 11, 12, 14, 17, 19, 20, 23, 24, 26, 27, 28, 29, 30,\\\n",
    "             32, 35, 36, 38, 41, 51, 52, 55, 60, 61]\n",
    "tgt_split = [ 1,  2,  3,  4,  7,  9, 10, 13, 15, 16, 18, 21, 22, 25, 31, 33,\\\n",
    "             34, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54,\\\n",
    "             56, 57, 58, 59]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start this demo by downloading a small dataset to test the FR system. This dataset is provided in the deepface repository and contains varying numbers of images of 13 different celebraties.\n",
    "\n",
    "Then, the dataset is divided into a database set and a target set. The database set will be used to create an initial database to run the recognition of the target set images against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to download the dataset in case 'dataset_path' does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the database and target splits' image paths & tags\n",
    "all_imgs = get_image_paths(stored_imgs_path)   # gets all image paths\n",
    "all_tags = person_name_lookup(all_imgs)        # gets the tag for each image\n",
    "\n",
    "db_imgs  = [all_imgs[i-1] for i in db_split]   # gets all database images\n",
    "tgt_imgs = [all_imgs[i-1] for i in tgt_split]  # gets all target images\n",
    "\n",
    "db_tags  = [all_tags[i-1] for i in db_split]   # gets all database tags\n",
    "#tgt_tags = [all_tags[i-1] for i in tgt_split]  # gets all target tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load all the relevant face verifier models. To keep things simple, we will only use one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load_face_verifier] Loading model ArcFace: success!\n",
      "\n",
      " {'ArcFace': <keras.engine.functional.Functional object at 0x7f06b17e8580>}\n"
     ]
    }
   ],
   "source": [
    "# Loading just the ArcFace model as this model will be used throughout this demo\n",
    "models = load_face_verifier([chosen_model], save_dir=svd_verifier_path,\n",
    "                            show_prog_bar=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the database from the *'db_imgs'* image set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating representations: 100%|| 26/26 [02:25<00:00,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "Creating faiss indexes for faster search: done!\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Tag: Angelina Jolie          |   Path: /home/rpessoa/projects/loki/dataset/img05.jpg    |   UID: 059a8fbf-cb26-49be-a29d-8d4c66fbb2f6\n",
      "Tag: Angelina Jolie          |   Path: /home/rpessoa/projects/loki/dataset/img06.jpg    |   UID: 228db835-934c-4399-a3c5-352a7141fb71\n",
      "Tag: Scarlett Johansson      |   Path: /home/rpessoa/projects/loki/dataset/img08.jpg    |   UID: 99e30e90-727b-4390-be4e-3b620fcdf67f\n",
      "Tag: Angelina Jolie          |   Path: /home/rpessoa/projects/loki/dataset/img11.jpg    |   UID: 372c96eb-bae3-4283-b2cc-2b4bdf002436\n",
      "Tag: Jennifer Aniston        |   Path: /home/rpessoa/projects/loki/dataset/img12.jpg    |   UID: e5f005ca-a6be-4034-9d3b-f86fbf760111\n",
      "Tag: Mark Zuckerberg         |   Path: /home/rpessoa/projects/loki/dataset/img14.jpg    |   UID: 47a3444e-efe1-4f3e-8cb5-d609719fc3de\n",
      "Tag: Jack Dorsey             |   Path: /home/rpessoa/projects/loki/dataset/img17.jpg    |   UID: 8cce5b03-97cd-4555-bb15-25affaff3d1e\n",
      "Tag: Elon Musk               |   Path: /home/rpessoa/projects/loki/dataset/img19.jpg    |   UID: 2bdd2fe1-7ff1-44f3-b298-0857964a953a\n",
      "Tag: Jeff Bezos              |   Path: /home/rpessoa/projects/loki/dataset/img20.jpg    |   UID: 8b79914d-cd15-4617-b63e-f5b8fbba59da\n",
      "Tag: Marissa Meyer           |   Path: /home/rpessoa/projects/loki/dataset/img23.jpg    |   UID: 960d434d-4863-4141-be3b-eba7c26de346\n",
      "Tag: Sundar Pichai           |   Path: /home/rpessoa/projects/loki/dataset/img24.jpg    |   UID: 3754200b-b190-4c24-8356-7145e9e5a085\n",
      "Tag: Katy Perry              |   Path: /home/rpessoa/projects/loki/dataset/img26.jpg    |   UID: 5a303041-5f97-40c0-b28e-90a0c5c0c8be\n",
      "Tag: Katy Perry              |   Path: /home/rpessoa/projects/loki/dataset/img27.jpg    |   UID: cdcaa39b-be5e-4c08-8efd-505ab30da587\n",
      "Tag: Katy Perry              |   Path: /home/rpessoa/projects/loki/dataset/img28.jpg    |   UID: 793c620d-e71f-469b-9245-9487c51f74fc\n",
      "Tag: Matt Damon              |   Path: /home/rpessoa/projects/loki/dataset/img29.jpg    |   UID: 54d13ce4-d2b4-4feb-bc9b-a689a2e5be4c\n",
      "Tag: Matt Damon              |   Path: /home/rpessoa/projects/loki/dataset/img30.jpg    |   UID: e21a83c3-8391-4f31-a67c-83e5d48bf6a8\n",
      "Tag: Matt Damon              |   Path: /home/rpessoa/projects/loki/dataset/img32.jpg    |   UID: 337176a4-0734-4dc4-a6a3-9a7812b21d0a\n",
      "Tag: Leonardo DiCaprio       |   Path: /home/rpessoa/projects/loki/dataset/img35.jpg    |   UID: d085aee4-69f0-4307-b0c0-fa0489d1db21\n",
      "Tag: Leonardo DiCaprio       |   Path: /home/rpessoa/projects/loki/dataset/img36.jpg    |   UID: f9f89aa4-08ff-453e-9882-65ea49898242\n",
      "Tag: George Clooney          |   Path: /home/rpessoa/projects/loki/dataset/img38.jpg    |   UID: 23c5e3fc-0ae9-4253-bc69-641ac7ae2d18\n",
      "Tag: George Clooney          |   Path: /home/rpessoa/projects/loki/dataset/img41.jpg    |   UID: b59267e7-d076-498b-8010-d00f233186c2\n",
      "Tag: Scarlett Johansson      |   Path: /home/rpessoa/projects/loki/dataset/img51.jpg    |   UID: cc424c93-4697-4b73-8eaf-3ac69ca8d691\n",
      "Tag: Jennifer Aniston        |   Path: /home/rpessoa/projects/loki/dataset/img53.jpg    |   UID: 6823da19-5444-44a5-a7fb-193f6af6e2c6\n",
      "Tag: Jennifer Aniston        |   Path: /home/rpessoa/projects/loki/dataset/img56.jpg    |   UID: 4df87223-9d00-4263-b452-92b117931c25\n",
      "Tag: Jack Dorsey             |   Path: /home/rpessoa/projects/loki/dataset/img62.jpg    |   UID: 61809e58-e580-4fb5-9b5d-6d4d9808e036\n",
      "Tag: Elon Musk               |   Path: /home/rpessoa/projects/loki/dataset/img67.jpg    |   UID: 4b6c5e20-2e6b-4ee7-b04e-e67fdc797273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Creates the representation database from the image paths\n",
    "rep_db = create_reps_from_dir(db_imgs, models, detector_name=chosen_backend,\n",
    "                align=align, verifier_names=chosen_model, show_prog_bar=True,\n",
    "                normalization=normalization, tags=db_tags, uids=[],\n",
    "                skip_get_imgs=True, verbose=False)\n",
    "\n",
    "# \n",
    "print('\\nCreating faiss indexes for faster search: ', end='')\n",
    "embds  = get_embeddings_as_array(rep_db, chosen_model)\n",
    "findex = create_faiss_index(embds, metric=metric)\n",
    "print('done!\\n')\n",
    "\n",
    "# - Print database summary\n",
    "for i in range(len(rep_db)):\n",
    "    print(f'Tag: {rep_db[i].name_tag}'.ljust(25),\n",
    "          f'Path: {rep_db[i].image_fp}',\n",
    "          f'UID: {rep_db[i].unique_id}', sep='    |   ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now verify each target image against the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying using FAISS:\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img01.jpg  |  sim1: [0, 3, 1]  |  sim2: [23 22  4]\n",
      "Target 0: img01.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img02.jpg  |  sim1: [1, 0, 3]  |  sim2: [23 22  4]\n",
      "Target 1: img02.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img03.jpg  |  sim1: [23, 22, 4]  |  sim2: [23 22  4]\n",
      "Target 2: img03.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img04.jpg  |  sim1: [0, 3, 1]  |  sim2: [23 22  4]\n",
      "Target 3: img04.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img07.jpg  |  sim1: [1, 3, 0, 23]  |  sim2: [23 22  4]\n",
      "Target 4: img07.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img09.jpg  |  sim1: [2, 21]  |  sim2: [23 22  4]\n",
      "Target 5: img09.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img10.jpg  |  sim1: [0, 3, 1]  |  sim2: [23 22  4]\n",
      "Target 6: img10.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img13.jpg  |  sim1: [5]  |  sim2: [23 22  4]\n",
      "Target 7: img13.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img15.jpg  |  sim1: [5]  |  sim2: [23 22  4]\n",
      "Target 8: img15.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img16.jpg  |  sim1: [6, 24, 14]  |  sim2: [23 22  4]\n",
      "Target 9: img16.jpg    (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img18.jpg  |  sim1: [7, 25]  |  sim2: [23 22  4]\n",
      "Target 10: img18.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img21.jpg  |  sim1: [8]  |  sim2: [23 22  4]\n",
      "Target 11: img21.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img22.jpg  |  sim1: [9, 0]  |  sim2: [23 22  4]\n",
      "Target 12: img22.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img25.jpg  |  sim1: [10]  |  sim2: [23 22  4]\n",
      "Target 13: img25.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img31.jpg  |  sim1: [14, 15, 16, 17]  |  sim2: [23 22  4]\n",
      "Target 14: img31.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img33.jpg  |  sim1: [15, 14, 16, 17]  |  sim2: [23 22  4]\n",
      "Target 15: img33.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img34.jpg  |  sim1: [18, 17]  |  sim2: [23 22  4]\n",
      "Target 16: img34.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img37.jpg  |  sim1: [18, 17]  |  sim2: [23 22  4]\n",
      "Target 17: img37.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img39.jpg  |  sim1: [20, 19]  |  sim2: [23 22  4]\n",
      "Target 18: img39.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img40.jpg  |  sim1: [20, 19]  |  sim2: [23 22  4]\n",
      "Target 19: img40.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img42.jpg  |  sim1: [12, 13, 11]  |  sim2: [23 22  4]\n",
      "Target 20: img42.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img43.jpg  |  sim1: [13, 11, 12]  |  sim2: [23 22  4]\n",
      "Target 21: img43.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img44.jpg  |  sim1: [13, 11, 12]  |  sim2: [23 22  4]\n",
      "Target 22: img44.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img45.jpg  |  sim1: [13, 11, 12]  |  sim2: [23 22  4]\n",
      "Target 23: img45.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img46.jpg  |  sim1: [13, 11, 12]  |  sim2: [23 22  4]\n",
      "Target 24: img46.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img47.jpg  |  sim1: [21, 2]  |  sim2: [23 22  4]\n",
      "Target 25: img47.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img48.jpg  |  sim1: [21, 2]  |  sim2: [23 22  4]\n",
      "Target 26: img48.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img49.jpg  |  sim1: [2, 21]  |  sim2: [23 22  4]\n",
      "Target 27: img49.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img50.jpg  |  sim1: [2, 21]  |  sim2: [23 22  4]\n",
      "Target 28: img50.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img54.jpg  |  sim1: [23, 4, 22]  |  sim2: [23 22  4]\n",
      "Target 29: img54.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img55.jpg  |  sim1: [23, 22, 4]  |  sim2: [23 22  4]\n",
      "Target 30: img55.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img57.jpg  |  sim1: [5]  |  sim2: [23 22  4]\n",
      "Target 31: img57.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img58.jpg  |  sim1: [5]  |  sim2: [23 22  4]\n",
      "Target 32: img58.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img59.jpg  |  sim1: [24, 6]  |  sim2: [23 22  4]\n",
      "Target 33: img59.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "Current pth: /home/rpessoa/projects/loki/dataset/img61.jpg  |  sim1: [24, 6]  |  sim2: [23 22  4]\n",
      "Target 34: img61.jpg   (verified: True  | name: Jennifer Aniston)  |  (found 3 matches)\n",
      "\n",
      "\n",
      " ----------------------------------------------------------------------------------------------------\n",
      "Verifying all (35) images took 222.246 seconds (approx 6.350 s/image)\n"
     ]
    }
   ],
   "source": [
    "if use_faiss:\n",
    "    print('Verifying using FAISS:')\n",
    "else:\n",
    "    print('Verifying without FAISS:')\n",
    "\n",
    "t_start = timer()   # initializes timer\n",
    "tgt_embeddings = [] # initializes target embeddings\n",
    "\n",
    "for i, pth in zip(range(len(tgt_imgs)), tgt_imgs):\n",
    "    # Check if a representation exists for the current image in the database\n",
    "    # NOTE: This is just an 'illustrative' step as all target images are new\n",
    "    rep, idx = find_image_in_db(pth, rep_db, shortcut=None) # for now, no representation exists\n",
    "\n",
    "    # Calculate the face image embedding and stores it\n",
    "    region, embedding = calc_embedding(pth, models, align=align,\n",
    "                                        detector_name=chosen_backend, \n",
    "                                        verifier_names=chosen_model,\n",
    "                                        normalization=normalization)\n",
    "    embedding = embedding[chosen_model] # since we are using 1 model, there will\n",
    "                                        # be a single embedding\n",
    "    tgt_embeddings.append(embedding)\n",
    "\n",
    "    # Calculates the similarity between the current embedding and the database\n",
    "    if use_faiss:\n",
    "        similarity_obj = verify_with_faiss(embedding[None, :], findex, rep_db,\n",
    "                                        top_x=top_x, model_name=chosen_model,\n",
    "                                        metric=metric, threshold=threshold)\n",
    "    else:\n",
    "        similarity_obj = calc_similarity(embedding, embds, metric=metric,\n",
    "                                   model_name=chosen_model, threshold=threshold)\n",
    "\n",
    "    # print('Current pth: {}'.format(pth),\n",
    "    #       'sim1: {}'.format(similarity_obj['idxs']),\n",
    "    #       'sim2: {}'.format(similarity_obj2['idxs']), sep='  |  ')\n",
    "\n",
    "    # Gets all matches\n",
    "    matches = [rep_db[i] for i in similarity_obj['idxs']]\n",
    "    \n",
    "    # Prints current iteration, image information and verification result\n",
    "    print('Target {}: {}'.format(i, pth.split('/')[-1]).ljust(22), end='')\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        print(' (verified: True  | name: {})  |  (found {} matches)'.format(\n",
    "                                    matches[0].name_tag, len(matches)))\n",
    "    else:\n",
    "        print(' (verified: False | name: ---)  |  (found 0 matches)')\n",
    "\n",
    "\n",
    "t_end = timer()\n",
    "print('\\n', '-' * 100)\n",
    "print('Verifying all ({}) images'.format(len(tgt_imgs)),\n",
    "      'took {:.3f} seconds'.format(t_end - t_start),\n",
    "      '(approx {:.3f} s/image)'.format((t_end - t_start) / len(tgt_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idxs': [23, 22, 4], 'threshold': 0.68, 'distances': [0.269162, 0.42606395, 0.54748183]} \n",
      "\n",
      "{'idxs': array([ 4, 22, 23]), 'threshold': 0.68, 'distances': [0.54748183, 0.42606395, 0.269162]}\n"
     ]
    }
   ],
   "source": [
    "print(similarity_obj, '\\n')\n",
    "print(similarity_obj2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idxs': [24, 6],\n",
       " 'threshold': 0.68,\n",
       " 'distances': array([0.3869403, 0.4511413], dtype=float32)}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_obj"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b8b4124e34c7aef84f71e2d1adc63dc40a11e5c939516b2a86977f9bc5888db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('loki_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
